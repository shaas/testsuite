#!/vol2/TCL_TK/glinux/bin/expect
#___INFO__MARK_BEGIN__
##########################################################################
#
#  The Contents of this file are made available subject to the terms of
#  the Sun Industry Standards Source License Version 1.2
#
#  Sun Microsystems Inc., March, 2001
#
#
#  Sun Industry Standards Source License Version 1.2
#  =================================================
#  The contents of this file are subject to the Sun Industry Standards
#  Source License Version 1.2 (the "License"); You may not use this file
#  except in compliance with the License. You may obtain a copy of the
#  License at http://gridengine.sunsource.net/Gridengine_SISSL_license.html
#
#  Software provided under this License is provided on an "AS IS" basis,
#  WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING,
#  WITHOUT LIMITATION, WARRANTIES THAT THE SOFTWARE IS FREE OF DEFECTS,
#  MERCHANTABLE, FIT FOR A PARTICULAR PURPOSE, OR NON-INFRINGING.
#  See the License for the specific provisions governing your rights and
#  obligations concerning the Software.
#
#  The Initial Developer of the Original Code is: Sun Microsystems, Inc.
#
#  Copyright: 2001 by Sun Microsystems, Inc.
#
#  All Rights Reserved.
#
##########################################################################
#___INFO__MARK_END__

# define global variable in this namespace
global check_name 
global check_category 
global check_description 
global check_needs
global check_functions 
global check_highest_level
global check_init_level_procedure
global check_root_access_needs
global env

set check_root_access_needs "yes"


# define a level initialization procedure:
set check_init_level_procedure "tight_integration_init_level"

# define test's name and run level descriptions
set check_name            "tight_integration"
set check_category        "COMPATIBILITY SYSTEM VERIFIED"
set check_highest_level   1
set check_description(0)  "check tightly integrated parallel jobs submitted with qsub"
set check_description(1)  "check tightly integrated parallel jobs submitted with qrsh"

# define test's dependencies
set check_needs           "init_core_system" 

# setup and cleanup functions
set check_setup_function tight_integration_setup
set check_cleanup_function tight_integration_cleanup

# define test's procedure order
set check_functions ""
lappend check_functions "tight_integration_function"
lappend check_functions "tight_integration_iz_578";# env vars NSLOTS and NHOSTS
lappend check_functions "tight_integration_master_killed"
lappend check_functions "tight_integration_slave_killed"
lappend check_functions "tight_integration_iz_575";# wallclock limit for tasks
lappend check_functions "tight_integration_iz_1916"
lappend check_functions "tight_integration_massive"

# constants to be used by the tight integration test
global TIGHT_INTEGRATION_FUNCTIONAL_SLOTS 
global TIGHT_INTEGRATION_FUNCTIONAL_DURATION
global TIGHT_INTEGRATION_MASSIVE_SLOTS
global TIGHT_INTEGRATION_MASSIVE_DURATION
global TIGHT_INTEGRATION_ERROR_MESSAGES
global TIGHT_INTEGRATION_WARNING_MESSAGES

set TIGHT_INTEGRATION_FUNCTIONAL_SLOTS 5
set TIGHT_INTEGRATION_FUNCTIONAL_DURATION 10
set TIGHT_INTEGRATION_MASSIVE_SLOTS 200
set TIGHT_INTEGRATION_MASSIVE_DURATION 120

proc tight_integration_init_level {} {
   global ts_config
   global CHECK_ACT_LEVEL
   global submit_command TIGHT_INTEGRATION_FUNCTIONAL_SLOTS

   # for the functional test we want to schedule one task to each host
   # we set the allocation rule to round_robin and request as many slots
   # as we have exec hosts
   set num_hosts [llength $ts_config(execd_nodes)]
   set TIGHT_INTEGRATION_FUNCTIONAL_SLOTS $num_hosts

   # tight integration with csp is not working in SGE(EE) 5.3
   if {$ts_config(gridengine_version) == 53 && $ts_config(product_feature) == "csp"} {
      return -1
   }

   switch -- $CHECK_ACT_LEVEL {
      "0" { 
         set submit_command qsub
         return 0    
      } 
      "1" {
         set submit_command qrsh
         return 0
      }
   } 

   return -1  ;# no other level 
}

# -------- local test procedures: initialization------------------------------

global submit_command

proc tight_integration_parse_execd_messages {mode} {
   global CHECK_PRODUCT_ROOT TIGHT_INTEGRATION_MASSIVE_SLOTS
   global ts_config CHECK_OUTPUT CHECK_USER
   global TIGHT_INTEGRATION_ERROR_MESSAGES TIGHT_INTEGRATION_WARNING_MESSAGES
   global tight_master_node
   #
   # Parse qmaster message file for warning and error messages. Note that we
   # may pick up old and stale messages as well.
   #
   puts $CHECK_OUTPUT "check messages file from qmaster on $tight_master_node..."
   set TIGHT_INTEGRATION_ERROR_MESSAGES("qmaster",$mode) 0
   set TIGHT_INTEGRATION_WARNING_MESSAGES("qmaster",$mode) 0
   set messages [ get_qmaster_messages_file ]
   get_file_content $tight_master_node $CHECK_USER $messages
   if { $file_array(0) < 1 } {
      add_proc_error "tight_integration_setup" -1 "no qmaster(host=$tight_master_node) messages file:\n$messages"
   }
   for {set i 1 } { $i <= $file_array(0) } { incr i 1 } {
      if { [string match "*|E|*" $file_array($i)] } {
         incr TIGHT_INTEGRATION_ERROR_MESSAGES("qmaster",$mode) 1
         set TIGHT_INTEGRATION_ERROR_MESSAGES("qmaster",$mode,$TIGHT_INTEGRATION_ERROR_MESSAGES("qmaster",$mode)) $file_array($i)
      }
      if { [string match "*|W|*" $file_array($i)] } {
         incr TIGHT_INTEGRATION_WARNING_MESSAGES("qmaster",$mode) 1
         set TIGHT_INTEGRATION_WARNING_MESSAGES("qmaster",$mode,$TIGHT_INTEGRATION_WARNING_MESSAGES("qmaster",$mode)) $file_array($i)
      }
   }
   #
   # Now, do the same whizzardry for each execd configured.
   #
   foreach execd $ts_config(execd_nodes) {
      puts $CHECK_OUTPUT "check messages file from execd $execd ..."
      set TIGHT_INTEGRATION_ERROR_MESSAGES($execd,$mode) 0
      set TIGHT_INTEGRATION_WARNING_MESSAGES($execd,$mode) 0
      set messages [ get_execd_messages_file $execd ]
      get_file_content $execd $CHECK_USER $messages 
      if { $file_array(0) < 1 } {
         add_proc_error "tight_integration_setup" -1 "no execd(host=$execd) messages file:\n$messages"
      }
      for {set i 1} {$i <= $file_array(0)} {incr i} {
         if {[string match "*|E|*" $file_array($i)]} {
            incr TIGHT_INTEGRATION_ERROR_MESSAGES($execd,$mode) 1
            set TIGHT_INTEGRATION_ERROR_MESSAGES($execd,$mode,$TIGHT_INTEGRATION_ERROR_MESSAGES($execd,$mode)) $file_array($i)
            #puts $CHECK_OUTPUT $file_array($i)
         }
         if {[string match "*|W|*" $file_array($i)]} {
            incr TIGHT_INTEGRATION_WARNING_MESSAGES($execd,$mode) 1
            set TIGHT_INTEGRATION_WARNING_MESSAGES($execd,$mode,$TIGHT_INTEGRATION_WARNING_MESSAGES($execd,$mode)) $file_array($i)
            #puts $CHECK_OUTPUT "$execd,$mode,$TIGHT_INTEGRATION_WARNING_MESSAGES($execd,$mode) = $file_array($i)"
         }
      }
   }

   puts $CHECK_OUTPUT "error   messages for qmaster $tight_master_node $mode: \
                       $TIGHT_INTEGRATION_ERROR_MESSAGES("qmaster",$mode)"
   puts $CHECK_OUTPUT "warning messages for qmaster $tight_master_node $mode: \
                       $TIGHT_INTEGRATION_WARNING_MESSAGES("qmaster",$mode)"

   foreach execd $ts_config(execd_nodes) {
      puts $CHECK_OUTPUT "error   messages for execd $execd: $TIGHT_INTEGRATION_ERROR_MESSAGES($execd,$mode)"
      puts $CHECK_OUTPUT "warning messages for execd $execd: $TIGHT_INTEGRATION_WARNING_MESSAGES($execd,$mode)"
   }
}


proc tight_integration_check_messages {mode1 mode2 scenario} {
   global CHECK_PRODUCT_ROOT TIGHT_INTEGRATION_MASSIVE_SLOTS
   global ts_config CHECK_OUTPUT CHECK_USER
   global TIGHT_INTEGRATION_ERROR_MESSAGES TIGHT_INTEGRATION_WARNING_MESSAGES

   set error_text ""
   #
   # OK, check if number of qmaster error messages has changed since test startup
   #
   if { $TIGHT_INTEGRATION_ERROR_MESSAGES("qmaster",$mode1) != $TIGHT_INTEGRATION_ERROR_MESSAGES("qmaster",$mode2) } {
      set header_written 0
      for { set i [expr ( $TIGHT_INTEGRATION_ERROR_MESSAGES("qmaster",$mode1) + 1 ) ] } \
       { $i <= $TIGHT_INTEGRATION_ERROR_MESSAGES("qmaster",$mode2) } { incr i 1 } {
         #
         # Loop over qmaster error messages generated during test run.
         #
         set message $TIGHT_INTEGRATION_ERROR_MESSAGES("qmaster",$mode2,$i)
         set mstart [ string last "|" $message ]
         incr mstart 1
         set skip_message 0
         #
         # We need to blank out qmaster messages that originate from fault injection.
         # There is one check per fault injections scenario.
         #
         if { $scenario == "master_killed" && \
               ( [ string match "*master task of job*" $message ] == 1 || \
                 [ string match "*died through signal KILL*" $message ] == 1 ) } {
            set skip_message 1
         } elseif { ( $scenario == "wallclock_test" || \
                      $scenario == "slave_killed" ) && \
                      ( [ string match "*killing job*" $message ] == 1 || \
                        [ string match "*died through signal KILL*" $message ] == 1 ) } {
            set skip_message 1
         }
         #
         # Write out any unexpected error message and header, if required.
         #
         if { $skip_message == 0 } {
            if { $header_written == 0 } {
               append error_text "tight integration check produced qmaster error messages at dagored:\n"
               set header_written 1
            }
            append error_text [string range "$message\n" $mstart end]
         }
      }
   }
   #
   # Next, check if number of qmaster warning messages has changed since test startup
   #
   if { $TIGHT_INTEGRATION_WARNING_MESSAGES("qmaster",$mode1) != $TIGHT_INTEGRATION_WARNING_MESSAGES("qmaster",$mode2) } {
      set header_written 0
      for { set i [expr ( $TIGHT_INTEGRATION_WARNING_MESSAGES("qmaster",$mode1) + 1 ) ] } \
       { $i <= $TIGHT_INTEGRATION_WARNING_MESSAGES("qmaster",$mode2) } { incr i 1 } {
         #
         # Loop over qmaster error messages generated during test run.
         #
         set message $TIGHT_INTEGRATION_WARNING_MESSAGES("qmaster",$mode2,$i)
         set mstart [ string last "|" $message ]
         incr mstart 1
         set skip_message 0
         #
         # We need to blank out qmaster messages that originate from fault injection.
         # There is one check per fault injections scenario.
         #
         if { ( $scenario == "reschedule_test" || \
                $scenario == "slave_killed" || \
                $scenario == "wallclock_test" || \
                $scenario == "master_killed" ) &&  \
              ( [ string match "*rescheduling because*" $message ] == 1 || \
                [ string match "*rescheduling job*" $message ] == 1 || \
                [ string match "*died through signal KILL*" $message ] == 1 ) } {
            set skip_message 1
         }
         #
         # Write out any unexpected warning message and header, if required.
         #
         if { $skip_message == 0 } {
            if { $header_written == 0 } {
               append error_text "tight integration check produced qmaster warning messages at dagored:\n"
               set header_written 1
            }
            append error_text [string range "$message\n" $mstart end]
         }
      }
   }
   foreach execd $ts_config(execd_nodes) {
      if {$TIGHT_INTEGRATION_ERROR_MESSAGES($execd,$mode1) != $TIGHT_INTEGRATION_ERROR_MESSAGES($execd,$mode2)} {
         puts $CHECK_OUTPUT "tight integration check produced execd error messages at $execd:"
         append error_text "tight integration check produced execd error messages at $execd:\n"
         for {set i [expr $TIGHT_INTEGRATION_ERROR_MESSAGES($execd,$mode1) + 1]} {$i <= $TIGHT_INTEGRATION_ERROR_MESSAGES($execd,$mode2)} {incr i 1} { 
            set message $TIGHT_INTEGRATION_ERROR_MESSAGES($execd,$mode2,$i)
            set mstart [string last "|" $message]
            incr mstart 1 
            append error_text [string range "$message\n" $mstart end]
         }
      }
      #
      # Check for new warning messages.
      #
      set header_written 0
      if {$TIGHT_INTEGRATION_WARNING_MESSAGES($execd,$mode1) != $TIGHT_INTEGRATION_WARNING_MESSAGES($execd,$mode2)} {
         #
         # Dump warning messages geerated during test run.
         #
         for {set i [expr $TIGHT_INTEGRATION_WARNING_MESSAGES($execd,$mode1) + 1]} {$i <= $TIGHT_INTEGRATION_WARNING_MESSAGES($execd,$mode2)} {incr i} {
            set message $TIGHT_INTEGRATION_WARNING_MESSAGES($execd,$mode2,$i)
            set mstart [string last "|" $message]
            incr mstart 1
            set skip_message 0
            set poo [ string map {" " "_"} $message ]
            #
            # We need to blank out execd messages that originate from fault injection.
            # There is one check per fault injections scenario.
            #
            if { $scenario == "wallclock_test" && [ string match "*exceeded_hard_wallclock*" $poo ] } {
               set skip_message 1
            }
            #
            # Write out any unexpected error message and header, if required.
            #
            if { $skip_message == 0 } {
               if { $header_written == 0 } {
                  puts $CHECK_OUTPUT "tight integration check produced execd warning messages at $execd:"
                  append error_text "tight integration check produced execd warning messages at $execd:\n"
                  set header_written 1
               }
               append error_text [string range "$message\n" $mstart end]
            }
         }
      }
   }

   if {$error_text != ""} {
      add_proc_error "tight_integration_check_messages" -3 "$error_text"
      puts $CHECK_OUTPUT "tight integration check produced error messages and/or warnings"
   } else {
      puts $CHECK_OUTPUT "tight integration check produced no execd errors or warnings"
   }
}

proc tight_integration_init_messages_check {} {
   tight_integration_parse_execd_messages startup
}

proc tight_integration_messages_check { scenario } {
   global CHECK_OUTPUT

   get_config global_config
   puts $CHECK_OUTPUT "load_report_time is set to $global_config(load_report_time)"
   set report_time [transform_date_time $global_config(load_report_time)]
   set zero_time [transform_date_time "00:00:00"]
   set sleep_time [expr $report_time - $zero_time]

   puts $CHECK_OUTPUT "sleeping for $sleep_time seconds to let each execd report its final state ..."
   sleep $sleep_time

   puts $CHECK_OUTPUT "additional sleep of 5 seconds ..."
   sleep 5

   puts $CHECK_OUTPUT "reading messages files ..."
   tight_integration_parse_execd_messages cleanup

   puts $CHECK_OUTPUT "compare error messages ..."
   tight_integration_check_messages startup cleanup $scenario
}

proc tight_integration_setup {} {
   global ts_config CHECK_OUTPUT
   global tight_masterq tight_master_node

   set tight_master_node $ts_config(master_host)
   set tight_masterq [get_queue_instance "tight.q" $tight_master_node]

   # shutdown and restart an execd
   # JG: Why?
if {0} {
   set execd_host [ lindex $ts_config(execd_nodes) 0 ]
   shutdown_system_daemon $execd_host execd
   startup_execd $execd_host
}
   # create parallel environment
   set pe(pe_name)            tight
   set pe(slots)              1000
   set pe(user_lists)         none
   set pe(xuser_lists)        none
   set pe(start_proc_args)    none
   set pe(stop_proc_args)     none
   set pe(allocation_rule)    "\$round_robin"
   set pe(control_slaves)     TRUE
   set pe(job_is_first_task)  FALSE
   add_pe pe

   # create a queue
   set queue_conf(load_thresholds) "np_load_avg=11"
   set queue_conf(slots) 10 
   set queue_conf(rerun) "true"
   add_queue tight.q "@allhosts" queue_conf

   # assign queue with pe
   assign_queues_with_pe_object tight.q "" tight
}

proc tight_integration_cleanup {} {
   global ts_config CHECK_OUTPUT

   delete_all_jobs
   wait_for_end_of_all_jobs 60

   unassign_queues_with_pe_object tight
   del_pe tight
   del_queue tight.q "" 0 1
}

# -------- local test procedures: utilities --------------------------
proc tight_integration_monitor {id started_var finished_var jobid_var info_var {iz_578 0}} {
   global CHECK_OUTPUT
   global tight_master_node

   upvar $started_var  started
   upvar $finished_var finished
   upvar $jobid_var    jobid
   upvar $info_var     info

   set ret "unknown"

   set sp_id [lindex $id 1]
   set timeout 180

   set unexpected_output ""
   
   expect_user {
      -i $sp_id timeout {
         add_proc_error tight_integration_monitor -1 "timeout waiting for tasks output (tight integration)"
         set ret "timeout"
      }
      -i $sp_id full_buffer {
         add_proc_error tight_integration_monitor -1 "buffer overflow please increment CHECK_EXPECT_MATCH_MAX_BUFFER value"
         set ret "error"
      }
      -i $sp_id eof {
         set ret "eof"
      }
      # workaround for a feature lacking in expect:
      # We have to parse complete lines.
      # expect_user ensures only that expect will parse input up to a newline,
      # but there seems to be no way to tell expect we want to examine each
      # individual line.
      -i $sp_id "?*\n" {
         #puts $CHECK_OUTPUT "entered default branch, data: $expect_out(0,string)"
         foreach line [string trim [split $expect_out(0,string) "\n"]] {
            set line [string trim $line]
            if {[string length $line] > 0} {
               #puts $CHECK_OUTPUT "processing line: $line"
               switch -glob $line {
                  "petask ??? with pid ???????? started on host*" {
                     set task [lindex $line 1]
                     lappend info(tasks) $task
                     set info($task,pid) [lindex $line 4]
                     set info($task,host) [lindex $line 8]
                     incr started
                     puts $CHECK_OUTPUT "task $task started, total started: $started"
                     set ret "task started"
                  }
                  "petask ??? with pid ???????? finished*" {
                     set task [lindex $line 1]
                     incr finished
                     puts $CHECK_OUTPUT "task $task finished, total finished: $finished"
                     set ret "task finished"
                  }
                  "master task started with job id ?????? and pid*" {
                     set jobid [lindex $line 6]
                     lappend info(tasks) master
                     set info(master,pid) [lindex $line 9]
                     set info(master,host) $tight_master_node
                     puts $CHECK_OUTPUT "job $jobid started"
                     set ret "master started"
                  }
                  "master task submitted all sub tasks*" {
                     puts $CHECK_OUTPUT "master task submitted all tasks"
                     set ret "master submitted"
                  }
                  "master task exiting*" {
                     puts $CHECK_OUTPUT "job $jobid exited"
                     set ret "master finished"
                  }
                  "NSLOTS ??? NHOSTS ??? NQUEUES*" {
                     if {$iz_578} {
                        set nslots  [lindex $line 1]
                        set nhosts  [lindex $line 3]
                        set nqueues [lindex $line 5]
                        puts $CHECK_OUTPUT "nslots = $nslots, nhosts = $nhosts, nqueues = $nqueues"
                        if {$nslots == 0 || $nhosts == 0 || $nqueues == 0} {
                           add_proc_error tight_integration_monitor -1 "invalid environment setting for NSLOTS, NHOSTS, NQUEUES for pe task (Issue 578 present): $line"
                           set ret "error"
                           break
                        }
                     }
                     set ret "task running"
                  }

                    
                  "_start_mark_:(*)*" {
                     puts $CHECK_OUTPUT "got start mark from remote prog shell script"
                  }
                  "_exit_status_:(*)*" {
                     puts $CHECK_OUTPUT "got exit status from remote prog shell script"
                  }
                  "script done.*" {
                     puts $CHECK_OUTPUT "got \"script done.\" from remote prog shell script"
                  }
                  default {
                     # something we didn't expect.
                     # store all unexpected lines and send them in one mail
                     # at the end
                     if {$unexpected_output != ""} {
                        append unexpected_output "\n"
                     }
                     append unexpected_output $line
                     set ret "unexpected job output"
                  }
               }
            }
         }
      }
   }

   # send unexpected output
   if {$unexpected_output != ""} {
      add_proc_error tight_integration_monitor -3 "unexpected job output:\n---\n$unexpected_output\n---\nPlease check our \".*\" login scripts for output lines!"
   }

   return $ret
}

proc tight_integration_job_finished {job_state} {
   global CHECK_OUTPUT

   switch -exact $job_state {
      "unknown" -
      "timeout" -
      "eof" -
      "master finished" -
      "error" {
         set job_finished 1
      }
      
      "task started" -
      "task running" -
      "task finished" -
      "master started" -
      "master submitted" -
      "unexpected job output" {
         set job_finished 0
      }

      default {
         set job_finished 1
      }
   }

   return $job_finished
}

proc tight_integration_wait_for_delete_state {jobid timeout} {
   global CHECK_OUTPUT

   set now [clock seconds]
   set end [expr $now + $timeout]
   while {$now < $end} {
      set state [lindex [get_job_state $jobid 1] 0]
      puts $CHECK_OUTPUT "job $jobid is in state $state"
      if {[string compare $state "dr"] == 0} {
         return 1
      } else {
         if {$state == -1} {
            puts $CHECK_OUTPUT "expected to see job $jobid in dr state, but job vanished. OK!"
            return 1
         }
      }
      set now [clock seconds]
      sleep 1
   }

   return 0
}

# -------- local test procedures: tests ------------------------------
proc tight_integration_function {} {
   global ts_config CHECK_OUTPUT
   global TIGHT_INTEGRATION_FUNCTIONAL_SLOTS TIGHT_INTEGRATION_FUNCTIONAL_DURATION
   global submit_command tight_masterq tight_master_node
   puts $CHECK_OUTPUT "tight_integration: functional test"

   set id [submit_with_method $submit_command "-pe tight $TIGHT_INTEGRATION_FUNCTIONAL_SLOTS -masterq $tight_masterq -cwd -N tightf" "$ts_config(testsuite_root_dir)/scripts/pe_job.sh" "$ts_config(testsuite_root_dir)/scripts/pe_task.sh 1 $TIGHT_INTEGRATION_FUNCTIONAL_DURATION" $tight_master_node]

   set started 0
   set finished 0
   set jobid 0
   set job_finished 0
   while {$job_finished == 0} {
      set job_state [tight_integration_monitor $id started finished jobid info]
      puts $CHECK_OUTPUT "job state: $job_state"
      set job_finished [tight_integration_job_finished $job_state]
   }

   if {$started != $TIGHT_INTEGRATION_FUNCTIONAL_SLOTS} {
      add_proc_error tight_integration_functional -1 "only $started tasks out of $TIGHT_INTEGRATION_FUNCTIONAL_SLOTS were started successfully"
   }

   if {$finished != $TIGHT_INTEGRATION_FUNCTIONAL_SLOTS} {
      add_proc_error tight_integration_functional -1 "only $finished tasks out of $TIGHT_INTEGRATION_FUNCTIONAL_SLOTS ran through successfully"
   }
   set sp_id [lindex $id 1]
   close_spawn_process $id

   wait_for_jobend $jobid tightf 60 0 1
}

# check if qmaster is killed on reschedule
proc tight_integration_iz_1916 {} {
   global ts_config CHECK_OUTPUT CHECK_USER 
   global CHECK_ACT_LEVEL 
   global TIGHT_INTEGRATION_FUNCTIONAL_DURATION
   global submit_command tight_masterq tight_master_node
   #
   # Initialize message processing.
   #
   tight_integration_init_messages_check

   puts $CHECK_OUTPUT "tight_integration: test iz 1916 (reschedule killes qmaster)"

   if {$CHECK_ACT_LEVEL != 0} {
      add_proc_error "tight_integration_iz_1916" -3 "rescheduling not supported for qrsh"
      return
   }

   if {$ts_config(gridengine_version) == 53} {
      add_proc_error "tight_integration_iz_1916" -3 "iz 1916 does not run in 5.3 systems"
      return
   }

   set TIGHT_INTEGRATION_FUNCTIONAL_SLOTS "4"
   
   # set global config to speed up the test
   get_config org_global_conf
   set global_conf(load_report_time) "00:00:01"
   set global_conf(max_unheard) "00:00:45"
   set_config global_conf
  
   # start job 

   set id [submit_with_method $submit_command "-pe tight $TIGHT_INTEGRATION_FUNCTIONAL_SLOTS -q $tight_masterq -cwd -N tightf" "$ts_config(testsuite_root_dir)/scripts/pe_job.sh" "$ts_config(testsuite_root_dir)/scripts/pe_task.sh 1 3600" $tight_master_node]

   set started 0
   set finished 0
   set jobid 0

   # wait until all tasks are started
   while {$started < $TIGHT_INTEGRATION_FUNCTIONAL_SLOTS} {
      set job_state [tight_integration_monitor $id started finished jobid info]
      puts $CHECK_OUTPUT "job state: $job_state"
      sleep 1
   }

   # wait for usage reports
   set online_info(cpu) 0
   set online_info(mem) 0
   set now [clock seconds]
   set end [expr $now + 45]

   while {$now < $end} {
      set my_timeout 1
      set timeout_error 0
      if {![get_qstat_j_info $jobid]} {
         add_proc_error test_name -1 "job terminated abnormally"
      } else {
         # get online usage
         foreach name [array names qstat_j_info] {
            if {[string compare [lindex $name 0] "usage"] == 0} {
               set usage_list [split $qstat_j_info($name) ","]
               set value_list [split [lindex $usage_list 0] "="]
               set online_cpu [parse_cpu_time [lindex $value_list 1]]
               set value_list [split [lindex $usage_list 1] "="]
               set online_mem [lindex [lindex $value_list 1] 0]
               
               set online_info(cpu) [max $online_info(cpu) $online_cpu]
               set online_info(mem) [max $online_info(mem) $online_mem]
            }
         }
         puts $CHECK_OUTPUT "job state: $job_state, cpu: $online_info(cpu), mem: $online_info(mem)"
      }
      if {$online_info(mem) > 0} {
         set now $end   
      } else {
         set now [clock seconds]
         sleep 1
      }
   }

   # reschedule job
   puts $CHECK_OUTPUT "sending qmod -rj to job $jobid"   
   
   set arch [resolve_arch $ts_config(master_host)]
   set qmod "$ts_config(product_root)/bin/$arch/qmod"
   set result [start_remote_prog $ts_config(master_host) $CHECK_USER $qmod "-rj $jobid"]
   
   #  puts $CHECK_OUTPUT $output
   puts $CHECK_OUTPUT "qmod returns $result"
   if {$prg_exit_state != 0} {
      add_proc_error "tight_integration_iz_1916" -1 "found the bug 1916"
      startup_qmaster 0 "" ""
   }

   delete_job $jobid 1

   close_spawn_process $id

   #
   # Check for warning/error messages and write out.
   #
   tight_integration_messages_check reschedule_test

   # reset global config
   set_config org_global_conf

}   

# check if tasks are killed when they hit a wallclock limit
proc tight_integration_iz_575 {} {
   global ts_config CHECK_OUTPUT CHECK_USER 
   global TIGHT_INTEGRATION_FUNCTIONAL_SLOTS TIGHT_INTEGRATION_FUNCTIONAL_DURATION
   global submit_command tight_masterq tight_master_node
   #
   # Initialize message processing.
   #
   tight_integration_init_messages_check

   puts $CHECK_OUTPUT "tight_integration: iz 575 task wallclock limit"

   if {$ts_config(gridengine_version) == 53} {
      add_proc_error "tight_integration_iz_575" -3 "iz 575 does not run in 5.3 systems"
      return
   }

   # set wallclock limit on all slave queues
   if {[llength $ts_config(execd_nodes)] < 2} {
      add_proc_error "tight_integration_iz_575" -3 "iz 575 test needs at least 2 execution hosts"
      return
   }

   set host_list [lrange $ts_config(execd_nodes) 1 end]

   set queue_conf(h_rt) "0:0:30"
   set_queue "tight.q" "$host_list" queue_conf

   # submit job
   set id [submit_with_method $submit_command "-pe tight $TIGHT_INTEGRATION_FUNCTIONAL_SLOTS -masterq $tight_masterq -cwd -N tightf" "$ts_config(testsuite_root_dir)/scripts/pe_job.sh" "$ts_config(testsuite_root_dir)/scripts/pe_task.sh 1 3600" $tight_master_node]

   set started 0
   set finished 0
   set jobid 0
   set job_finished 0

   # wait until all tasks are started
   while {$job_finished == 0 && $started < $TIGHT_INTEGRATION_FUNCTIONAL_SLOTS} {
      set job_state [tight_integration_monitor $id started finished jobid info]
      puts $CHECK_OUTPUT "job state: $job_state"
      set job_finished [tight_integration_job_finished $job_state]
   }

   # if startup was ok
   if {$job_finished == 0} {
      # job has to go into deleted state after rt limit - allow for 5s delay
      if {![tight_integration_wait_for_delete_state $jobid 35]} {
         add_proc_error "tight_integration_iz_575" -1 "slave tasks should have been killed due to runtime limit and set the job into dr state - issue 575 present"
         delete_job $jobid
      }
   }
   set sp_id [lindex $id 1]
   close_spawn_process $id

   wait_for_jobend $jobid tightf 60 0 1

   # reset queue runtime limit
   set queue_conf(h_rt) "INFINITY"
   set_queue "tight.q" "$host_list" queue_conf
   #
   # Check for warning/error messages and write out.
   #
   tight_integration_messages_check wallclock_test
}

# check NSLOTS, NHOSTS, NQUEUES for tasks
proc tight_integration_iz_578 {} {
   global ts_config CHECK_OUTPUT 
   global TIGHT_INTEGRATION_FUNCTIONAL_SLOTS TIGHT_INTEGRATION_FUNCTIONAL_DURATION
   global submit_command tight_masterq tight_master_node
   puts $CHECK_OUTPUT "tight_integration: Issue 578 NSLOTS NHOSTS NQUEUES"
   #
   # Initialize message processing.
   #
   tight_integration_init_messages_check


   set id [submit_with_method $submit_command "-pe tight $TIGHT_INTEGRATION_FUNCTIONAL_SLOTS -masterq $tight_masterq -cwd -N tightf" "$ts_config(testsuite_root_dir)/scripts/pe_job.sh" "$ts_config(testsuite_root_dir)/scripts/pe_task.sh 1 $TIGHT_INTEGRATION_FUNCTIONAL_DURATION" $tight_master_node]


   set started 0
   set finished 0
   set jobid 0
   set job_finished 0
   while {$job_finished == 0} {
      set job_state [tight_integration_monitor $id started finished jobid info 1]
      puts $CHECK_OUTPUT "job state: $job_state"
      set job_finished [tight_integration_job_finished $job_state]
   }
   set sp_id [lindex $id 1]
   close_spawn_process $id

   wait_for_jobend $jobid tightf 60 0 1
   #
   # Check for new warning/error messages and write out.
   #
   tight_integration_messages_check iz_578
}

# master task killed -> job has to be deleted
proc tight_integration_master_killed {} {
   global ts_config CHECK_OUTPUT CHECK_USER
   global TIGHT_INTEGRATION_FUNCTIONAL_SLOTS TIGHT_INTEGRATION_FUNCTIONAL_DURATION
   global submit_command tight_masterq tight_master_node
   puts $CHECK_OUTPUT "tight_integration: master task killed - issue 579"

   #
   # Initialize message processing.
   #
   set id [submit_with_method $submit_command "-pe tight $TIGHT_INTEGRATION_FUNCTIONAL_SLOTS -masterq $tight_masterq -cwd -N tightf" "$ts_config(testsuite_root_dir)/scripts/pe_job.sh" "$ts_config(testsuite_root_dir)/scripts/pe_task.sh 1 3600" $tight_master_node]

   set started 0
   set finished 0
   set jobid 0
   set job_finished 0

   # wait until all tasks are started
   while {$job_finished == 0 && $started < $TIGHT_INTEGRATION_FUNCTIONAL_SLOTS} {
      set job_state [tight_integration_monitor $id started finished jobid info]
      puts $CHECK_OUTPUT "job state: $job_state"
      set job_finished [tight_integration_job_finished $job_state]
   }

   # if startup was ok
   if {$job_finished == 0} {
      # wait for job to be running
      wait_for_job_state $jobid "r" 120

      # kill pid of master task and wait some seconds
      puts $CHECK_OUTPUT "killing process group of master task: pid $info(master,pid) on host $info(master,host)"
      start_remote_prog $info(master,host) "ts_def_con2" kill "-9 -$info(master,pid)"

      if {![tight_integration_wait_for_delete_state $jobid 60]} {
         add_proc_error "tight_integration_master_killed" -1 "failed master task does not cause the job to be deleted (issue 579 present)"
         delete_job $jobid
      }
   }

   set sp_id [lindex $id 1]
   close_spawn_process $id

   wait_for_jobend $jobid tightf 60 0 1
   #
   # Check for new warning/error messages and write out.
   #
   tight_integration_messages_check master_killed

}

# slave task killed -> job has to be deleted
proc tight_integration_slave_killed {} {
   global ts_config CHECK_OUTPUT CHECK_USER
   global TIGHT_INTEGRATION_FUNCTIONAL_SLOTS TIGHT_INTEGRATION_FUNCTIONAL_DURATION
   global submit_command tight_masterq tight_master_node
   puts $CHECK_OUTPUT "tight_integration: slave task killed"

   #
   # Initialize message processing.
   #
   tight_integration_init_messages_check

   set hosts_to_check {}
   set resolved_master [resolve_host $tight_master_node]
   foreach host $ts_config(execd_nodes) {
      set resolved_host [resolve_host $host] 
      if { $resolved_host != $resolved_master } {
         lappend hosts_to_check $resolved_host
      }
   }


   set failures ""
   set ok_text ""
   while { [llength $hosts_to_check] > 0 } {

      set id [submit_with_method $submit_command "-pe tight $TIGHT_INTEGRATION_FUNCTIONAL_SLOTS -masterq $tight_masterq -cwd -N tightf" "$ts_config(testsuite_root_dir)/scripts/pe_job.sh" "$ts_config(testsuite_root_dir)/scripts/pe_task.sh 1 3600" $tight_master_node]

      set started 0
      set finished 0
      set jobid 0
      set job_finished 0

      # wait until all tasks are started
      while {$job_finished == 0 && $started < $TIGHT_INTEGRATION_FUNCTIONAL_SLOTS} {
         set job_state [tight_integration_monitor $id started finished jobid info]
         puts $CHECK_OUTPUT "job state: $job_state"
         set job_finished [tight_integration_job_finished $job_state]
      }

      # if startup was ok
      set success 0
      if {$job_finished == 0} {
         set success 1
         # wait for job to be running
         wait_for_job_state $jobid "r" 120

         for {set i 0 } {$i < [llength $ts_config(execd_nodes) ]} {incr i 1} {
            puts $CHECK_OUTPUT "task host $i: $info($i,host)"
            puts $CHECK_OUTPUT "             pid: $info($i,pid)"
            set resolved_host [resolve_host $info($i,host)]
            if { [string compare [lindex $hosts_to_check 0] $resolved_host] == 0 } {
               set kill_task_nr $i
               puts $CHECK_OUTPUT "killing task $i this time (host=$resolved_host)!"
               set hosts_to_check [lrange $hosts_to_check 1 end]
               puts $CHECK_OUTPUT "kill hosts to test: $hosts_to_check"
               break
            }
         }

         # kill pid of slave task and wait some seconds
         puts $CHECK_OUTPUT "killing slave task: process group $info($kill_task_nr,pid) on host $info($kill_task_nr,host)"
         set output [start_remote_prog $info($kill_task_nr,host) "ts_def_con2" kill "-9 -$info($kill_task_nr,pid)"]
         puts $CHECK_OUTPUT "kill as ts_def_con2 ($CHECK_USER) kill -9 -$info($kill_task_nr,pid) returned:\n$output"
         if {![tight_integration_wait_for_delete_state $jobid 60]} {
            set success 0
         }
      } else {
         append failures "not all jobs seems to have started\n"
      }

      set sp_id [lindex $id 1]
      close_spawn_process $id

      if { $success == 0 } {
         append failures "failed slave task does not cause the job to be deleted when task was killed on host $info($kill_task_nr,host)\n"
         delete_job $jobid
      } else {
         append ok_text "successfully tested \"tight_integration_slave_killed\" on host $info($kill_task_nr,host)\n"
      }
      wait_for_jobend $jobid tightf 60 0 1
   }
   if { $failures != "" } {
      add_proc_error "tight_integration_slave_killed" -1 "failures:\n$failures\ntest was ok for:\n$ok_text"
   }
   #
   # Check for new warning/error messages and write out.
   #
   tight_integration_messages_check slave_killed

}

proc tight_integration_massive {} {
   global ts_config CHECK_OUTPUT
   global TIGHT_INTEGRATION_MASSIVE_SLOTS TIGHT_INTEGRATION_MASSIVE_DURATION
   global submit_command tight_masterq tight_master_node
   puts $CHECK_OUTPUT "tight_integration: massive parallel test"

   # count the number of slots in the cluster to check if tests can be run
   set total_slots 0
   foreach host $ts_config(execd_nodes) {
      get_queue [get_queue_instance "tight.q" $host] queue_conf
      incr total_slots $queue_conf(slots)
      unset queue_conf
   }

   # increase the number of slots util maximum is reached
   for {set massive_slots 19} {$massive_slots <= $TIGHT_INTEGRATION_MASSIVE_SLOTS} {incr massive_slots 10} {
      puts $CHECK_OUTPUT "running parallel job with $massive_slots slots"
      # check if test can run at all in this cluster
      if {$total_slots < [expr $massive_slots + 1]} {
         add_proc_error tight_integration_massive -3 "test cannot run massive parallel job with $massive_slots tasks + the master task - cluster only has $total_slots slots"
         return
      }

      set id [submit_with_method $submit_command "-pe tight $massive_slots -masterq $tight_masterq -cwd -N tightm" "$ts_config(testsuite_root_dir)/scripts/pe_job.sh" "$ts_config(testsuite_root_dir)/scripts/pe_task.sh 1 $TIGHT_INTEGRATION_MASSIVE_DURATION" $tight_master_node]

      set started 0
      set finished 0
      set jobid 0
      set job_finished 0
      
      while {$job_finished == 0} {
         set job_state [tight_integration_monitor $id started finished jobid info]
         set job_finished [tight_integration_job_finished $job_state]
      }

      if {$started != $massive_slots} {
         add_proc_error tight_integration_massive -1 "only $started tasks out of $massive_slots were started successfully"
      }

      if {$finished != $massive_slots} {
         add_proc_error tight_integration_massive -1 "only $finished tasks out of $massive_slots ran through successfully"
      }
      set sp_id [lindex $id 1]
      close_spawn_process $id

      wait_for_jobend $jobid tightm 300 0 1
   }
}
