#!/vol2/TCL_TK/glinux/bin/expect
#___INFO__MARK_BEGIN__
##########################################################################
#
#  The Contents of this file are made available subject to the terms of
#  the Sun Industry Standards Source License Version 1.2
#
#  Sun Microsystems Inc., March, 2001
#
#
#  Sun Industry Standards Source License Version 1.2
#  =================================================
#  The contents of this file are subject to the Sun Industry Standards
#  Source License Version 1.2 (the "License"); You may not use this file
#  except in compliance with the License. You may obtain a copy of the
#  License at http://gridengine.sunsource.net/Gridengine_SISSL_license.html
#
#  Software provided under this License is provided on an "AS IS" basis,
#  WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING,
#  WITHOUT LIMITATION, WARRANTIES THAT THE SOFTWARE IS FREE OF DEFECTS,
#  MERCHANTABLE, FIT FOR A PARTICULAR PURPOSE, OR NON-INFRINGING.
#  See the License for the specific provisions governing your rights and
#  obligations concerning the Software.
#
#  The Initial Developer of the Original Code is: Sun Microsystems, Inc.
#
#  Copyright: 2001 by Sun Microsystems, Inc.
#
#  All Rights Reserved.
#
##########################################################################
#___INFO__MARK_END__

# define global variable in this namespace
global check_name 
global check_category 
global check_description 
global check_needs
global check_functions 
global check_highest_level
global check_init_level_procedure
global check_root_access_needs
global env

set check_root_access_needs "yes"


# define a level initialization procedure:
set check_init_level_procedure "tight_integration_init_level"

# define test's name and run level descriptions
set check_name            "tight_integration"
set check_category        "COMPATIBILITY SYSTEM VERIFIED"
set check_highest_level   2
set check_description(0)  "check tightly integrated parallel jobs submitted with qsub"
set check_description(1)  "check tightly integrated parallel jobs submitted with qrsh"
set check_description(2)  "check tightly integrated parallel jobs submitted with qrsh, accounting summary"

# define test's dependencies
set check_needs           "init_core_system" 

# setup and cleanup functions
set check_setup_function tight_integration_setup
set check_cleanup_function tight_integration_cleanup
set check_setup_level_function tight_integration_setup_level

# define test's procedure order
set check_functions ""
lappend check_functions "tight_integration_function"
lappend check_functions "tight_integration_iz_578";# env vars NSLOTS and NHOSTS
lappend check_functions "tight_integration_master_killed"
lappend check_functions "tight_integration_slave_killed"
lappend check_functions "tight_integration_iz_575";# wallclock limit for tasks
lappend check_functions "tight_integration_iz_1916"
lappend check_functions "tight_integration_massive"
lappend check_functions "tight_integration_massive_nfs_tmpdir"
lappend check_functions "tight_integration_massive_short"
# This tests needs to be the last one
lappend check_functions "tight_integration_check_tmpdir"

# constants to be used by the tight integration test
global TIGHT_INTEGRATION_FUNCTIONAL_SLOTS 
global TIGHT_INTEGRATION_FUNCTIONAL_DURATION
global TIGHT_INTEGRATION_MASSIVE_SLOTS
global TIGHT_INTEGRATION_MASSIVE_DURATION
global TIGHT_INTEGRATION_ERROR_MESSAGES
global TIGHT_INTEGRATION_WARNING_MESSAGES

set TIGHT_INTEGRATION_FUNCTIONAL_SLOTS 5
set TIGHT_INTEGRATION_FUNCTIONAL_DURATION 10
set TIGHT_INTEGRATION_MASSIVE_SLOTS 200
set TIGHT_INTEGRATION_MASSIVE_DURATION 120

proc tight_integration_init_level {} {
   global ts_config
   global CHECK_ACT_LEVEL

   # tight integration with csp is not working in SGE(EE) 5.3
   if {$ts_config(gridengine_version) == 53 && $ts_config(product_feature) == "csp"} {
      return -1
   }

   switch -- $CHECK_ACT_LEVEL {
      0 {
         return 0
      }
      1 {
         return 0
      }
      2 {
         if {$ts_config(gridengine_version) >= 62 && ![is_61AR]} {
            return 0
         }
      }
   }

   return -1  ;# no other level
}

proc tight_integration_setup {} {
   global ts_config
   global CHECK_ACT_LEVEL
   global TIGHT_INTEGRATION_FUNCTIONAL_SLOTS
   global tight_masterq tight_master_node
   global tight_global_config

   # we have to set a short load report time
   # to workaround CR 6728379
   get_config tight_global_config

   # for the functional test we want to schedule one task to each host
   # we set the allocation rule to round_robin and request as many slots
   # as we have exec hosts
   set num_hosts [llength $ts_config(execd_nodes)]
   set TIGHT_INTEGRATION_FUNCTIONAL_SLOTS $num_hosts

   set tight_master_node $ts_config(master_host)
   set tight_masterq [get_queue_instance "tight.q" $tight_master_node]

   # create parallel environment
   set pe(slots)              1000
   set pe(user_lists)         none
   set pe(xuser_lists)        none
   set pe(start_proc_args)    none
   set pe(stop_proc_args)     none
   set pe(allocation_rule)    "\$round_robin"
   set pe(control_slaves)     TRUE
   set pe(job_is_first_task)  FALSE
   add_pe tight pe

   # create a queue
   set queue_conf(load_thresholds) "np_load_avg=11"
   set queue_conf(slots) 10
   set queue_conf(rerun) "true"
   add_queue "tight.q" "@allhosts" queue_conf

   # assign queue with pe
   assign_queues_with_pe_object tight.q "" tight

   cleanup_tmpdirs
}

proc tight_integration_setup_level {} {
   global ts_config
   global CHECK_ACT_LEVEL
   global submit_command tight_integration_accounting_summary

   set tight_integration_accounting_summary 0

   switch -- $CHECK_ACT_LEVEL {
      0 {
         set submit_command qsub
      }
      1 {
         set submit_command qrsh
      }
      2 {
         set submit_command qrsh
         set tight_integration_accounting_summary 1
      }
   }
   
   # in level 2, we test with pe setting accounting_summary true
   if {$tight_integration_accounting_summary} {
      set pe(accounting_summary) "TRUE"
   } else {
      if {$ts_config(gridengine_version) >= 62 && ![is_61AR]} {
         set pe(accounting_summary) "FALSE"
      }
   }

   mod_pe "tight" pe
}

proc tight_integration_cleanup {} {
   global ts_config
   global tight_global_config

   set_config_and_propagate tight_global_config

   delete_all_jobs
   wait_for_end_of_all_jobs 60

   unassign_queues_with_pe_object "tight"
   del_pe "tight"
   del_queue "tight.q" "" 0 1
}

# -------- local test procedures: initialization------------------------------

proc tight_integration_parse_execd_messages {mode} {
   global TIGHT_INTEGRATION_MASSIVE_SLOTS
   global ts_config CHECK_USER
   global TIGHT_INTEGRATION_ERROR_MESSAGES TIGHT_INTEGRATION_WARNING_MESSAGES
   global tight_master_node
   #
   # Parse qmaster message file for warning and error messages. Note that we
   # may pick up old and stale messages as well.
   #
   ts_log_fine "check messages file from qmaster on $tight_master_node..."
   set TIGHT_INTEGRATION_ERROR_MESSAGES("qmaster",$mode) 0
   set TIGHT_INTEGRATION_WARNING_MESSAGES("qmaster",$mode) 0
   set messages [get_qmaster_messages_file]
   get_file_content $tight_master_node $CHECK_USER $messages
   if {$file_array(0) < 1} {
      ts_log_severe "no qmaster(host=$tight_master_node) messages file:\n$messages"
   }
   for {set i 1} {$i <= $file_array(0)} {incr i 1} {
      if {[string match "*|E|*" $file_array($i)]} {
         incr TIGHT_INTEGRATION_ERROR_MESSAGES("qmaster",$mode) 1
         set TIGHT_INTEGRATION_ERROR_MESSAGES("qmaster",$mode,$TIGHT_INTEGRATION_ERROR_MESSAGES("qmaster",$mode)) $file_array($i)
      }
      if {[string match "*|W|*" $file_array($i)]} {
         incr TIGHT_INTEGRATION_WARNING_MESSAGES("qmaster",$mode) 1
         set TIGHT_INTEGRATION_WARNING_MESSAGES("qmaster",$mode,$TIGHT_INTEGRATION_WARNING_MESSAGES("qmaster",$mode)) $file_array($i)
      }
   }
   #
   # Now, do the same whizzardry for each execd configured.
   #
   foreach execd $ts_config(execd_nodes) {
      ts_log_fine "check messages file from execd $execd ..."
      set TIGHT_INTEGRATION_ERROR_MESSAGES($execd,$mode) 0
      set TIGHT_INTEGRATION_WARNING_MESSAGES($execd,$mode) 0
      set messages [get_execd_messages_file $execd]
      get_file_content $execd $CHECK_USER $messages 
      if {$file_array(0) < 1} {
         ts_log_severe "no execd(host=$execd) messages file:\n$messages"
      }
      for {set i 1} {$i <= $file_array(0)} {incr i} {
         if {[string match "*|E|*" $file_array($i)]} {
            incr TIGHT_INTEGRATION_ERROR_MESSAGES($execd,$mode) 1
            set TIGHT_INTEGRATION_ERROR_MESSAGES($execd,$mode,$TIGHT_INTEGRATION_ERROR_MESSAGES($execd,$mode)) $file_array($i)
            #ts_log_fine $file_array($i)
         }
         if {[string match "*|W|*" $file_array($i)]} {
            incr TIGHT_INTEGRATION_WARNING_MESSAGES($execd,$mode) 1
            set TIGHT_INTEGRATION_WARNING_MESSAGES($execd,$mode,$TIGHT_INTEGRATION_WARNING_MESSAGES($execd,$mode)) $file_array($i)
            #ts_log_fine "$execd,$mode,$TIGHT_INTEGRATION_WARNING_MESSAGES($execd,$mode) = $file_array($i)"
         }
      }
   }

   ts_log_fine "error   messages for qmaster $tight_master_node $mode: \
                       $TIGHT_INTEGRATION_ERROR_MESSAGES("qmaster",$mode)"
   ts_log_fine "warning messages for qmaster $tight_master_node $mode: \
                       $TIGHT_INTEGRATION_WARNING_MESSAGES("qmaster",$mode)"

   foreach execd $ts_config(execd_nodes) {
      ts_log_fine "error   messages for execd $execd: $TIGHT_INTEGRATION_ERROR_MESSAGES($execd,$mode)"
      ts_log_fine "warning messages for execd $execd: $TIGHT_INTEGRATION_WARNING_MESSAGES($execd,$mode)"
   }
}


proc tight_integration_check_messages {mode1 mode2 scenario {expect_error 0}} {
   global TIGHT_INTEGRATION_MASSIVE_SLOTS
   global ts_config CHECK_USER
   global TIGHT_INTEGRATION_ERROR_MESSAGES TIGHT_INTEGRATION_WARNING_MESSAGES

   set error_text ""
   #
   # OK, check if number of qmaster error messages has changed since test startup
   #
   if {$TIGHT_INTEGRATION_ERROR_MESSAGES("qmaster",$mode1) != $TIGHT_INTEGRATION_ERROR_MESSAGES("qmaster",$mode2)} {
      set header_written 0
      for {set i [expr ( $TIGHT_INTEGRATION_ERROR_MESSAGES("qmaster",$mode1) + 1 )]} \
       {$i <= $TIGHT_INTEGRATION_ERROR_MESSAGES("qmaster",$mode2)} {incr i} {
         #
         # Loop over qmaster error messages generated during test run.
         #
         set message $TIGHT_INTEGRATION_ERROR_MESSAGES("qmaster",$mode2,$i)
         set mstart [string last "|" $message]
         incr mstart 1
         set skip_message 0
         #
         # We need to blank out qmaster messages that originate from fault injection.
         # There is one check per fault injections scenario.
         #
         if {$scenario == "master_killed" && \
               ([string match "*master task of job*" $message] == 1 || \
                [string match "*died through signal KILL*" $message] == 1)} {
            set skip_message 1
         } elseif {($scenario == "wallclock_test" || \
                    $scenario == "slave_killed" ) && \
                    ([string match "*killing job*" $message] == 1 || \
                     [string match "*died through signal KILL*" $message] == 1)} {
            set skip_message 1
         }
         #
         # Write out any unexpected error message and header, if required.
         #
         if {$skip_message == 0} {
            if {$header_written == 0} {
               append error_text "tight integration check produced qmaster error messages at $ts_config(master_host):\n"
               set header_written 1
            }
            append error_text [string range "$message\n" $mstart end]
         }
      }
   }
   #
   # Next, check if number of qmaster warning messages has changed since test startup
   #
   if {$TIGHT_INTEGRATION_WARNING_MESSAGES("qmaster",$mode1) != $TIGHT_INTEGRATION_WARNING_MESSAGES("qmaster",$mode2)} {
      set header_written 0
      for {set i [expr ($TIGHT_INTEGRATION_WARNING_MESSAGES("qmaster",$mode1) + 1)]} \
       {$i <= $TIGHT_INTEGRATION_WARNING_MESSAGES("qmaster",$mode2)} {incr i 1} {
         #
         # Loop over qmaster error messages generated during test run.
         #
         set message $TIGHT_INTEGRATION_WARNING_MESSAGES("qmaster",$mode2,$i)
         set mstart [string last "|" $message]
         incr mstart 1
         set skip_message 0
         #
         # We need to blank out qmaster messages that originate from fault injection.
         # There is one check per fault injections scenario.
         #
         if {($scenario == "reschedule_test" || \
              $scenario == "slave_killed" || \
              $scenario == "wallclock_test" || \
              $scenario == "master_killed") && \
              ([string match "*rescheduling because*" $message] == 1 || \
               [string match "*rescheduling job*" $message] == 1 || \
               [string match "*died through signal KILL*" $message] == 1)} {
            set skip_message 1
         }
         #
         # Write out any unexpected warning message and header, if required.
         #
         if {$skip_message == 0} {
            if {$header_written == 0} {
               append error_text "tight integration check produced qmaster warning messages at $ts_config(master_host):\n"
               set header_written 1
            }
            append error_text [string range "$message\n" $mstart end]
         }
      }
   }
   foreach execd $ts_config(execd_nodes) {
      if {$TIGHT_INTEGRATION_ERROR_MESSAGES($execd,$mode1) != $TIGHT_INTEGRATION_ERROR_MESSAGES($execd,$mode2)} {
         ts_log_fine "tight integration check produced execd error messages at $execd:"
         append error_text "tight integration check produced execd error messages at $execd:\n"
         for {set i [expr $TIGHT_INTEGRATION_ERROR_MESSAGES($execd,$mode1) + 1]} {$i <= $TIGHT_INTEGRATION_ERROR_MESSAGES($execd,$mode2)} {incr i 1} { 
            set message $TIGHT_INTEGRATION_ERROR_MESSAGES($execd,$mode2,$i)
            set mstart [string last "|" $message]
            incr mstart 1 
            append error_text [string range "$message\n" $mstart end]
         }
      }
      #
      # Check for new warning messages.
      #
      set header_written 0
      if {$TIGHT_INTEGRATION_WARNING_MESSAGES($execd,$mode1) != $TIGHT_INTEGRATION_WARNING_MESSAGES($execd,$mode2)} {
         #
         # Dump warning messages geerated during test run.
         #
         for {set i [expr $TIGHT_INTEGRATION_WARNING_MESSAGES($execd,$mode1) + 1]} {$i <= $TIGHT_INTEGRATION_WARNING_MESSAGES($execd,$mode2)} {incr i} {
            set message $TIGHT_INTEGRATION_WARNING_MESSAGES($execd,$mode2,$i)
            set mstart [string last "|" $message]
            incr mstart 1
            set skip_message 0
            set poo [string map {" " "_"} $message]
            #
            # We need to blank out execd messages that originate from fault injection.
            # There is one check per fault injections scenario.
            #
            if {$scenario == "wallclock_test" && [string match "*exceeded_hard_wallclock*" $poo]} {
               set skip_message 1
            }
            #
            # Write out any unexpected error message and header, if required.
            #
            if {$skip_message == 0} {
               if {$header_written == 0} {
                  ts_log_fine "tight integration check produced execd warning messages at $execd:"
                  append error_text "tight integration check produced execd warning messages at $execd:\n"
                  set header_written 1
               }
               append error_text [string range "$message\n" $mstart end]
            }
         }
      }
   }

   if {$error_text != ""} {
      if {$expect_error} {
         ts_log_info $error_text
      } else {
         ts_log_severe $error_text
      }
      ts_log_fine "tight integration check produced error messages and/or warnings"
   } else {
      ts_log_fine "tight integration check produced no execd errors or warnings"
   }
}

proc tight_integration_init_messages_check {} {
   tight_integration_parse_execd_messages startup
}

proc tight_integration_messages_check {scenario {expect_error 0}} {
   get_config global_config
   ts_log_fine "load_report_time is set to $global_config(load_report_time)"
   set report_time [transform_date_time $global_config(load_report_time)]
   set zero_time [transform_date_time "00:00:00"]
   set sleep_time [expr $report_time - $zero_time]

   ts_log_fine "sleeping for $sleep_time seconds to let each execd report its final state ..."
   after [expr $sleep_time * 1000]

   ts_log_fine "additional sleep of 5 seconds ..."
   after 5000

   ts_log_fine "reading messages files ..."
   tight_integration_parse_execd_messages cleanup

   ts_log_fine "compare error messages ..."
   tight_integration_check_messages startup cleanup $scenario $expect_error
}

# -------- local test procedures: utilities --------------------------
proc tight_integration_wait_for_delete_state {jobid timeout} {
   set now [clock seconds]
   set end [expr $now + $timeout]
   while {$now < $end} {
      set state [lindex [get_job_state $jobid 1] 0]
      ts_log_fine "job $jobid is in state $state"
      if {[string compare $state "dr"] == 0} {
         return 1
      } else {
         if {$state == -1} {
             ts_log_info "expected to see job $jobid in dr state, but job vanished. OK !?"
            return 1
         }
      }
      set now [clock seconds]
      after 1000
   }

   return 0
}

# -------- local test procedures: tests ------------------------------
proc tight_integration_function {} {
   global ts_config
   global TIGHT_INTEGRATION_FUNCTIONAL_SLOTS TIGHT_INTEGRATION_FUNCTIONAL_DURATION
   global submit_command tight_masterq tight_master_node
   ts_log_fine "tight_integration: functional test"

   set id [submit_with_method $submit_command "-pe tight $TIGHT_INTEGRATION_FUNCTIONAL_SLOTS -masterq $tight_masterq -cwd -N tightf" "$ts_config(testsuite_root_dir)/scripts/pe_job.sh" "$ts_config(testsuite_root_dir)/scripts/pe_task.sh 1 $TIGHT_INTEGRATION_FUNCTIONAL_DURATION" $tight_master_node]

   set started 0
   set finished 0
   set jobid 0
   set job_finished 0
   while {$job_finished == 0} {
      set job_state [tight_integration_monitor $id $tight_master_node started finished jobid info]
      ts_log_fine "job state: $job_state"
      set job_finished [tight_integration_job_finished $job_state]
   }

   if {$started != $TIGHT_INTEGRATION_FUNCTIONAL_SLOTS} {
      ts_log_severe "only $started tasks out of $TIGHT_INTEGRATION_FUNCTIONAL_SLOTS were started successfully"
   }

   if {$finished != $TIGHT_INTEGRATION_FUNCTIONAL_SLOTS} {
      ts_log_severe "only $finished tasks out of $TIGHT_INTEGRATION_FUNCTIONAL_SLOTS ran through successfully"
   }
   set sp_id [lindex $id 1]
   close_spawn_process $id

   wait_for_jobend $jobid tightf 60 0 1
   tight_integration_acct $jobid $TIGHT_INTEGRATION_FUNCTIONAL_SLOTS
}

# check if qmaster is killed on reschedule
proc tight_integration_iz_1916 {} {
   global ts_config CHECK_USER 
   global CHECK_ACT_LEVEL 
   global TIGHT_INTEGRATION_FUNCTIONAL_DURATION
   global submit_command tight_masterq tight_master_node
   #
   # Initialize message processing.
   #
   tight_integration_init_messages_check

   ts_log_fine "tight_integration: test iz 1916 (reschedule kills qmaster)"

   if {$CHECK_ACT_LEVEL != 0} {
      ts_log_config "rescheduling not supported for qrsh"
      return
   }

   if {$ts_config(gridengine_version) == 53} {
      ts_log_config "iz 1916 does not run in 5.3 systems"
      return
   }

   set TIGHT_INTEGRATION_FUNCTIONAL_SLOTS "4"
   
   # set global config to speed up the test
   get_config org_global_conf
   set global_conf(load_report_time) "00:00:01"
   set global_conf(max_unheard) "00:00:45"
   set_config global_conf
  
   # start job 

   set id [submit_with_method $submit_command "-pe tight $TIGHT_INTEGRATION_FUNCTIONAL_SLOTS -q $tight_masterq -cwd -N tightf" "$ts_config(testsuite_root_dir)/scripts/pe_job.sh" "$ts_config(testsuite_root_dir)/scripts/pe_task.sh 1 3600" $tight_master_node]

   set started 0
   set finished 0
   set jobid 0

   # wait until all tasks are started
   while {$started < $TIGHT_INTEGRATION_FUNCTIONAL_SLOTS} {
      set job_state [tight_integration_monitor $id $tight_master_node started finished jobid info]
      ts_log_fine "job state: $job_state"
      after 1000
   }

   # wait for usage reports
   set online_info(cpu) 0
   set online_info(mem) 0
   set now [clock seconds]
   set end [expr $now + 45]

   while {$now < $end} {
      set my_timeout 1
      set timeout_error 0
      if {![get_qstat_j_info $jobid]} {
         ts_log_severe "job terminated abnormally"
      } else {
         # get online usage
         foreach name [array names qstat_j_info] {
            if {[string compare [lindex $name 0] "usage"] == 0} {
               set usage_list [split $qstat_j_info($name) ","]
               set value_list [split [lindex $usage_list 0] "="]
               set online_cpu [parse_cpu_time [lindex $value_list 1]]
               set value_list [split [lindex $usage_list 1] "="]
               set online_mem [lindex [lindex $value_list 1] 0]
               
               set online_info(cpu) [max $online_info(cpu) $online_cpu]
               set online_info(mem) [max $online_info(mem) $online_mem]
            }
         }
         ts_log_fine "job state: $job_state, cpu: $online_info(cpu), mem: $online_info(mem)"
      }
      if {$online_info(mem) > 0} {
         set now $end   
      } else {
         set now [clock seconds]
         after 1000
      }
   }

   # reschedule job
   ts_log_fine "sending qmod -rj to job $jobid"   
   set result [start_sge_bin "qmod" "-rj $jobid"]
   
   #  ts_log_fine $output
   ts_log_fine "qmod returns $result"
   if {$prg_exit_state != 0} {
      ts_log_severe "found the bug 1916"
      startup_qmaster 0 "" ""
   }

   delete_job $jobid 1

   close_spawn_process $id

   #
   # Check for warning/error messages and write out.
   #
   # we expect to have error messages in messages file
   # probably will be fixed with CR 6244911: qmod -r does not delete the old instance
   #                                         of a job before a new one is started
   # TODO: if CR 6244911, test and remove the expect_error 1
   tight_integration_messages_check reschedule_test 1

   # reset global config
   set_config org_global_conf
}

# check if tasks are killed when they hit a wallclock limit
proc tight_integration_iz_575 {} {
   global ts_config CHECK_USER 
   global TIGHT_INTEGRATION_FUNCTIONAL_SLOTS TIGHT_INTEGRATION_FUNCTIONAL_DURATION
   global submit_command tight_masterq tight_master_node
   #
   # Initialize message processing.
   #
   tight_integration_init_messages_check

   ts_log_fine "tight_integration: iz 575 task wallclock limit"

   if {$ts_config(gridengine_version) == 53} {
      ts_log_config "iz 575 does not run in 5.3 systems"
      return
   }

   # set wallclock limit on all slave queues
   if {[llength $ts_config(execd_nodes)] < 2} {
      ts_log_config "iz 575 test needs at least 2 execution hosts"
      return
   }

   set host_list [lrange $ts_config(execd_nodes) 1 end]

   set queue_conf(h_rt) "0:0:30"
   set_queue "tight.q" $host_list queue_conf

   # submit job
   set id [submit_with_method $submit_command "-pe tight $TIGHT_INTEGRATION_FUNCTIONAL_SLOTS -masterq $tight_masterq -cwd -N tightf" "$ts_config(testsuite_root_dir)/scripts/pe_job.sh" "$ts_config(testsuite_root_dir)/scripts/pe_task.sh 1 3600" $tight_master_node]

   set started 0
   set finished 0
   set jobid 0
   set job_finished 0

   # wait until all tasks are started
   while {$job_finished == 0 && $started < $TIGHT_INTEGRATION_FUNCTIONAL_SLOTS} {
      set job_state [tight_integration_monitor $id $tight_master_node started finished jobid info]
      ts_log_fine "job state: $job_state"
      set job_finished [tight_integration_job_finished $job_state]
   }

   # if startup was ok
   if {$job_finished == 0} {
      # job has to go into deleted state after rt limit - allow for 5s delay
      if {![tight_integration_wait_for_delete_state $jobid 35]} {
         ts_log_severe "slave tasks should have been killed due to runtime limit and set the job into dr state - issue 575 present"
         delete_job $jobid
      }
   }
   set sp_id [lindex $id 1]
   close_spawn_process $id

   wait_for_jobend $jobid tightf 60 0 1

   # reset queue runtime limit
   set queue_conf(h_rt) "INFINITY"
   set_queue "tight.q" "$host_list" queue_conf
   #
   # Check for warning/error messages and write out.
   #
   tight_integration_messages_check wallclock_test
}

# check NSLOTS, NHOSTS, NQUEUES for tasks
proc tight_integration_iz_578 {} {
   global ts_config
   global TIGHT_INTEGRATION_FUNCTIONAL_SLOTS TIGHT_INTEGRATION_FUNCTIONAL_DURATION
   global submit_command tight_masterq tight_master_node
   ts_log_fine "tight_integration: Issue 578 NSLOTS NHOSTS NQUEUES"
   #
   # Initialize message processing.
   #
   tight_integration_init_messages_check


   set id [submit_with_method $submit_command "-pe tight $TIGHT_INTEGRATION_FUNCTIONAL_SLOTS -masterq $tight_masterq -cwd -N tightf" "$ts_config(testsuite_root_dir)/scripts/pe_job.sh" "$ts_config(testsuite_root_dir)/scripts/pe_task.sh 1 $TIGHT_INTEGRATION_FUNCTIONAL_DURATION" $tight_master_node]


   set started 0
   set finished 0
   set jobid 0
   set job_finished 0
   while {$job_finished == 0} {
      set job_state [tight_integration_monitor $id $tight_master_node started finished jobid info 1]
      ts_log_fine "job state: $job_state"
      set job_finished [tight_integration_job_finished $job_state]
   }
   set sp_id [lindex $id 1]
   close_spawn_process $id

   wait_for_jobend $jobid tightf 60 0 1
   #
   # Check for new warning/error messages and write out.
   #
   tight_integration_messages_check iz_578
}

# master task killed -> job has to be deleted
proc tight_integration_master_killed {} {
   global ts_config CHECK_USER
   global TIGHT_INTEGRATION_FUNCTIONAL_SLOTS TIGHT_INTEGRATION_FUNCTIONAL_DURATION
   global submit_command tight_masterq tight_master_node
   ts_log_fine "tight_integration: master task killed - issue 579"

   #
   # Initialize message processing.
   #
   tight_integration_init_messages_check

   set id [submit_with_method $submit_command "-pe tight $TIGHT_INTEGRATION_FUNCTIONAL_SLOTS -masterq $tight_masterq -cwd -N tightf" "$ts_config(testsuite_root_dir)/scripts/pe_job.sh" "$ts_config(testsuite_root_dir)/scripts/pe_task.sh 1 3600" $tight_master_node]

   set started 0
   set finished 0
   set jobid 0
   set job_finished 0

   # wait until all tasks are started
   while {$job_finished == 0 && $started < $TIGHT_INTEGRATION_FUNCTIONAL_SLOTS} {
      set job_state [tight_integration_monitor $id $tight_master_node started finished jobid info]
      ts_log_fine "job state: $job_state"
      set job_finished [tight_integration_job_finished $job_state]
   }

   # if startup was ok
   if {$job_finished == 0} {
      # wait for job to be running
      wait_for_job_state $jobid "r" 120

      # kill pid of master task and wait some seconds
      ts_log_fine "killing process group of master task: pid $info(master,pid) on host $info(master,host)"
      start_remote_prog $info(master,host) $CHECK_USER kill "-9 -$info(master,pid)"

      if {![tight_integration_wait_for_delete_state $jobid 60]} {
         ts_log_severe "failed master task does not cause the job to be deleted (issue 579 present)"
         delete_job $jobid
      }
   }

   set sp_id [lindex $id 1]
   close_spawn_process $id

   wait_for_jobend $jobid tightf 60 0 1
   #
   # Check for new warning/error messages and write out.
   #
   tight_integration_messages_check master_killed
}

# slave task killed -> job has to be deleted
proc tight_integration_slave_killed {} {
   global ts_config CHECK_USER
   global TIGHT_INTEGRATION_FUNCTIONAL_SLOTS TIGHT_INTEGRATION_FUNCTIONAL_DURATION
   global submit_command tight_masterq tight_master_node
   ts_log_fine "tight_integration: slave task killed"

   #
   # Initialize message processing.
   #
   tight_integration_init_messages_check

   set hosts_to_check {}
   set resolved_master [resolve_host $tight_master_node]
   foreach host $ts_config(execd_nodes) {
      set resolved_host [resolve_host $host] 
      if { $resolved_host != $resolved_master } {
         lappend hosts_to_check $resolved_host
      }
   }


   set failures ""
   set ok_text ""
   while {[llength $hosts_to_check] > 0} {
      set id [submit_with_method $submit_command "-pe tight $TIGHT_INTEGRATION_FUNCTIONAL_SLOTS -masterq $tight_masterq -cwd -N tightf" "$ts_config(testsuite_root_dir)/scripts/pe_job.sh" "$ts_config(testsuite_root_dir)/scripts/pe_task.sh 1 3600" $tight_master_node]

      set started 0
      set finished 0
      set jobid 0
      set job_finished 0

      # wait until all tasks are started
      while {$job_finished == 0 && $started < $TIGHT_INTEGRATION_FUNCTIONAL_SLOTS} {
         set job_state [tight_integration_monitor $id $tight_master_node started finished jobid info]
         ts_log_fine "job state: $job_state"
         set job_finished [tight_integration_job_finished $job_state]
      }

      # if startup was ok
      set success 0
      if {$job_finished == 0} {
         set success 1
         # wait for job to be running
         wait_for_job_state $jobid "r" 120

         for {set i 0} {$i < [llength $ts_config(execd_nodes)]} {incr i 1} {
            ts_log_fine "task host $i: $info($i,host)"
            ts_log_fine "             pid: $info($i,pid)"
            set resolved_host [resolve_host $info($i,host)]
            if {[string compare [lindex $hosts_to_check 0] $resolved_host] == 0} {
               set kill_task_nr $i
               ts_log_fine "killing task $i this time (host=$resolved_host)!"
               set hosts_to_check [lrange $hosts_to_check 1 end]
               ts_log_fine "kill hosts to test: $hosts_to_check"
               break
            }
         }

         # kill pid of slave task and wait some seconds
         ts_log_fine "killing slave task: process group $info($kill_task_nr,pid) on host $info($kill_task_nr,host)"
         set output [start_remote_prog $info($kill_task_nr,host) $CHECK_USER kill "-9 -$info($kill_task_nr,pid)"]
         ts_log_fine "kill as $CHECK_USER kill -9 -$info($kill_task_nr,pid)\n$output"
         if {![tight_integration_wait_for_delete_state $jobid 60]} {
            set success 0
         }
      } else {
         append failures "not all jobs seems to have started\n"
      }

      set sp_id [lindex $id 1]
      close_spawn_process $id

      if {$success == 0} {
         append failures "failed slave task does not cause the job to be deleted when task was killed on host $info($kill_task_nr,host)\n"
         delete_job $jobid
      } else {
         append ok_text "successfully tested \"tight_integration_slave_killed\" on host $info($kill_task_nr,host)\n"
      }
      wait_for_jobend $jobid tightf 60 0 1
   }
   if {$failures != ""} {
      ts_log_severe "failures:\n$failures\ntest was ok for:\n$ok_text"
   }
   #
   # Check for new warning/error messages and write out.
   #
   tight_integration_messages_check slave_killed
}

proc tight_integration_massive {} {
   global ts_config
   global TIGHT_INTEGRATION_MASSIVE_SLOTS TIGHT_INTEGRATION_MASSIVE_DURATION
   global submit_command tight_masterq tight_master_node
   ts_log_fine "tight_integration: massive parallel test"

   # count the number of slots in the cluster to check if tests can be run
   set total_slots 0
   foreach host $ts_config(execd_nodes) {
      get_queue [get_queue_instance "tight.q" $host] queue_conf
      incr total_slots $queue_conf(slots)
      unset queue_conf
   }

   # Cluster big enough?
   # We'll run the test anyways.
   if {$total_slots < $TIGHT_INTEGRATION_MASSIVE_SLOTS} {
      ts_log_config "cannot start massive parallel job with $TIGHT_INTEGRATION_MASSIVE_SLOTS slots, using the maximum size provided by the cluster: $total_slots"
   }

   ts_log_fine "running parallel job with $total_slots slots"

   set id [submit_with_method $submit_command "-pe tight $total_slots -masterq $tight_masterq -cwd -N tightm" "$ts_config(testsuite_root_dir)/scripts/pe_job.sh" "$ts_config(testsuite_root_dir)/scripts/pe_task.sh 1 $TIGHT_INTEGRATION_MASSIVE_DURATION" $tight_master_node]

   set started 0
   set finished 0
   set jobid 0
   set job_finished 0
   
   while {$job_finished == 0} {
      set job_state [tight_integration_monitor $id $tight_master_node started finished jobid info]
      set job_finished [tight_integration_job_finished $job_state]
   }

   if {$started != $total_slots} {
      ts_log_severe "job $jobid: only $started tasks out of $total_slots were started successfully"
   }

   if {$finished != $total_slots} {
      ts_log_severe "job $jobid: only $finished tasks out of $total_slots ran through successfully"
   }
   set sp_id [lindex $id 1]
   close_spawn_process $id

   wait_for_jobend $jobid tightm 300 0 1
   tight_integration_acct $jobid $total_slots
}

proc tight_integration_massive_nfs_tmpdir {} {
   global ts_config
   global CHECK_USER
   global TIGHT_INTEGRATION_MASSIVE_SLOTS TIGHT_INTEGRATION_MASSIVE_DURATION
   global submit_command tight_masterq tight_master_node
   ts_log_fine "tight_integration: massive parallel test with tmpdir on NFS"

   # initialize checking of messages files
   tight_integration_init_messages_check

   # count the number of slots in the cluster to check if tests can be run
   set tmpdir "$ts_config(product_root)/tight_tmpdir"
   set fileserver [fs_config_get_server_for_path $tmpdir]
   remote_file_mkdir $fileserver $tmpdir
   set total_slots 0
   foreach host $ts_config(execd_nodes) {
      set qinstance [get_queue_instance "tight.q" $host]
      get_queue  $qinstance queue_conf
      incr total_slots $queue_conf(slots)
      unset queue_conf

      # setup a tmpdir on NFS - an individual one per host
      set host_tmpdir "$tmpdir/$host"
      remote_file_mkdir $fileserver $host_tmpdir
      wait_for_remote_dir $host $CHECK_USER $host_tmpdir
      mqattr tmpdir $host_tmpdir $qinstance
   }

   ts_log_fine "running parallel job with $total_slots slots"

   set id [submit_with_method $submit_command "-pe tight $total_slots -masterq $tight_masterq -cwd -N tightm" "$ts_config(testsuite_root_dir)/scripts/pe_job.sh" "$ts_config(testsuite_root_dir)/scripts/pe_task.sh 1 $TIGHT_INTEGRATION_MASSIVE_DURATION" $tight_master_node]

   set started 0
   set finished 0
   set jobid 0
   set job_finished 0
   
   while {$job_finished == 0} {
      set job_state [tight_integration_monitor $id $tight_master_node started finished jobid info]
      set job_finished [tight_integration_job_finished $job_state]
   }

   if {$started != $total_slots} {
      ts_log_severe "job $jobid: only $started tasks out of $total_slots were started successfully"
   }

   if {$finished != $total_slots} {
      ts_log_severe "job $jobid: only $finished tasks out of $total_slots ran through successfully"
   }
   set sp_id [lindex $id 1]
   close_spawn_process $id

   wait_for_jobend $jobid tightm 300 0 1
   tight_integration_acct $jobid $total_slots

   # reset queue settings
   foreach host $ts_config(execd_nodes) {
      set qinstance [get_queue_instance "tight.q" $host]
      start_sge_bin "qconf" "-purge queue tmpdir $qinstance"
   }
   delete_directory $tmpdir

   # now check if master or execd's reported any problems
   tight_integration_messages_check massive_nfs_tmpdir
}

proc tight_integration_acct {job_id num_tasks} {
   global tight_integration_accounting_summary
   get_current_cluster_config_array ts_config
   # in level 2, we do the accounting summary
   # expect only one accounting record
   # else the number of tasks records
   if {$tight_integration_accounting_summary} {
      set expected 1
   } else {
      set expected [expr $num_tasks + 1]
   }
   get_qacct $job_id qacct_info $ts_config(master_host) "" 1 $expected 30

   # re-check
   set num_acct [llength $qacct_info(exit_status)]
   if {$tight_integration_accounting_summary} {
      if {$num_acct != 1} {
         ts_log_severe "job $job_id: expected only one accounting record with accounting_summary enabled, but got $num_qacct"
      }
   } else { 
      set expected [expr $num_tasks + 1]
      if {$num_acct != $expected} {
         ts_log_severe "job $job_id: expected $expected accounting records, but got $num_acct"
      }
   }

   # in 6.0u13 and higher, the submission time of tasks is specified; in older version it was 0.
   # check that all submission times are in an interval of 5 minutes
   if {$ts_config(gridengine_version) >= 60 && ![is_61AR]} {
      set min [clock scan "tomorrow"]; set max 0
      foreach time $qacct_info(qsub_time) {
         if {$time < $min} {
            set min $time
         }
         if {$time > $max} {
            set max $time
         }
      }
      if {[expr $max - $min] > 300} {
         ts_log_severe "job $job_id: tightly integrated job and tasks were not started within 5 minutes, or tasks accounting records do not contain correct submission time:\n$qacct_info(qsub_time)"
      }
   }
}

proc tight_integration_massive_short {} {
   global ts_config
   global TIGHT_INTEGRATION_MASSIVE_SLOTS TIGHT_INTEGRATION_MASSIVE_DURATION
   global submit_command tight_masterq tight_master_node

   ts_log_fine "tight_integration: massive parallel test with short tasks"

   # initialize checking of messages files
   tight_integration_init_messages_check

   # count the number of slots in the cluster to check if tests can be run
   set total_slots 0
   foreach host $ts_config(execd_nodes) {
      get_queue [get_queue_instance "tight.q" $host] queue_conf
      incr total_slots $queue_conf(slots)
      unset queue_conf
   }

   ts_log_fine "running parallel job with $total_slots slots"

   set id [submit_with_method $submit_command "-pe tight $total_slots -masterq $tight_masterq -cwd -N tightm" "$ts_config(testsuite_root_dir)/scripts/pe_job.sh" "$ts_config(testsuite_root_dir)/scripts/pe_task.sh 1 1" $tight_master_node]

   set started 0
   set finished 0
   set jobid 0
   set job_finished 0
   
   while {$job_finished == 0} {
      set job_state [tight_integration_monitor $id $tight_master_node started finished jobid info]
      set job_finished [tight_integration_job_finished $job_state]
   }

   if {$started != $total_slots} {
      ts_log_severe "job $jobid: only $started tasks out of $total_slots were started successfully"
   }

   if {$finished != $total_slots} {
      ts_log_severe "job $jobid: only $finished tasks out of $total_slots ran through successfully"
   }
   set sp_id [lindex $id 1]
   close_spawn_process $id

   wait_for_jobend $jobid tightm 300 0 1
   tight_integration_acct $jobid $total_slots
   tight_integration_messages_check massive_short
}

proc tight_integration_check_tmpdir {} {
   global CHECK_USER ts_config

   set error ""
   set tmpdir "/tmp/testsuite_$ts_config(commd_port)"

   foreach host $ts_config(execd_nodes) {
      set output [start_remote_prog $host $CHECK_USER ls "$tmpdir"]
      set output [string trim $output] 
      if { $output != "" } {
         append error "Found IZ 2846: tmpdir was not cleaned on host $host for jobs: $output\n"
      }
   }
   if { $error != "" } {
      ts_log_severe "$error"
   }
}

