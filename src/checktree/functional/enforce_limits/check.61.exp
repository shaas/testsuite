#!/vol2/TCL_TK/glinux/bin/expect
#___INFO__MARK_BEGIN__
##########################################################################
#
#  The Contents of this file are made available subject to the terms of
#  the Sun Industry Standards Source License Version 1.2
#
#  Sun Microsystems Inc., March, 2001
#
#
#  Sun Industry Standards Source License Version 1.2
#  =================================================
#  The contents of this file are subject to the Sun Industry Standards
#  Source License Version 1.2 (the "License"); You may not use this file
#  except in compliance with the License. You may obtain a copy of the
#  License at http://gridengine.sunsource.net/Gridengine_SISSL_license.html
#
#  Software provided under this License is provided on an "AS IS" basis,
#  WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING,
#  WITHOUT LIMITATION, WARRANTIES THAT THE SOFTWARE IS FREE OF DEFECTS,
#  MERCHANTABLE, FIT FOR A PARTICULAR PURPOSE, OR NON-INFRINGING.
#  See the License for the specific provisions governing your rights and
#  obligations concerning the Software.
#
#  The Initial Developer of the Original Code is: Sun Microsystems, Inc.
#
#  Copyright: 2008 by Sun Microsystems, Inc.
#
#  All Rights Reserved.
#
##########################################################################
#___INFO__MARK_END__

# define global variable in this namespace
global check_name 
global check_category 
global check_description 
global check_needs
global check_functions 
global check_highest_level
global check_init_level_procedure
global check_root_access_needs

set check_root_access_needs "yes"

# define a level initialization procedure:
set check_init_level_procedure "enforce_limits_init_level"

# define test's name and run level descriptions
set check_name            "enforce_limits"
set check_category        "COMPATIBILITY SYSTEM VERIFIED"
set check_highest_level   0 
set check_description(0)  ""
set check_description(1)  ""

# define test's dependencies
set check_needs           "init_core_system" 

# setup and cleanup functions
set check_setup_function enforce_limits_setup
set check_cleanup_function enforce_limits_cleanup

# define test's procedure order
set check_functions {}
lappend check_functions "enforce_limits_tight_execd_limit_enforcement_after_stop_start"
lappend check_functions "enforce_limits_tight_qmaster_limit_enforcement_master_queue"
lappend check_functions "enforce_limits_tight_qmaster_forced_all_queue"
lappend check_functions "enforce_limits_tight_execd_limit_enforcement"
lappend check_functions "enforce_limits_tight_qmaster_limit_enforcement_slave_queue"
lappend check_functions "enforce_limits_tight_qmaster_limit_enforcement_all_queue"
lappend check_functions "enforce_limits_loose_qmaster_limit_enforcement_all_queue"
lappend check_functions "enforce_limits_batch_qmaster_limit_enforcement_all_queue"
lappend check_functions "enforce_limits_tight_qmaster_limit_enforcement_after_stop_start_master"
lappend check_functions "enforce_limits_tight_qmaster_limit_enforcement_after_stop_start_slave"

# constants
set tight_slots 5

proc enforce_limits_init_level {} {
   global CHECK_ACT_LEVEL
   global ts_config

   switch -- $CHECK_ACT_LEVEL {
      0 -
      1 {
         if {$ts_config(gridengine_version) >= 62 || [is_61AR]} {
            return 0
         }
      }
   }

   return -1  ;# no other level
}

# -------- local test procedures: initialization------------------------------

# 01) startup cluster
# 02) create a PE
#    - use round robin
#    - tight pe  
#    - create a machine file containing all hosts
# 03) create a PE
#    - use round robin
#    - loose pe  
# 04) select N hosts (at least 2)
# 05) create a queue QUEUE
#    - h_rt = 30 sec
#    - pelist has to contain PE
# 06) change several parameters
#    - load report interval of all hosts to 5 seconds
#    - ENABLE_ENFORCE_MASTER_LIMIT=1
proc enforce_limits_setup {} {
   global ts_config
   global CHECK_ACT_LEVEL
   global tight_slots
   global tight_masterq 
   global tight_master_node
   global tight_slaveq
   global tight_slave_node
   global loose_slots
   global loose_masterq 
   global loose_master_node
   global loose_slaveq
   global loose_slave_node
   global el_base_path
   global org_global_conf

   set el_base_path $ts_config(testsuite_root_dir)/checktree/functional/enforce_limits

   # for the functional test we want to schedule one task to each host
   # we set the allocation rule to round_robin and request as many slots
   # as we have exec hosts
   set num_hosts [llength $ts_config(execd_nodes)]
   set tight_slots $num_hosts

   set tight_master_node $ts_config(master_host)
   set tight_slave_node [lindex $ts_config(execd_nodes) 0]
   if {$tight_slave_node == $tight_master_node} {
      # use the next host if the current one is the master host
      set tight_slave_node [lindex $ts_config(execd_nodes) 1]
   }
   set tight_masterq [get_queue_instance "tight.q" $tight_master_node]
   set tight_slaveq [get_queue_instance "tight.q" $tight_slave_node]

   set loose_slots $tight_slots
   set loose_master_node $tight_master_node
   set loose_slave_node $tight_slave_node
   set loose_masterq [get_queue_instance "loose.q" $loose_master_node]
   set loose_slaveq [get_queue_instance "loose.q" $loose_slave_node]

   # create parallel environment (tight integration)
   set pe(slots)              1000
   set pe(user_lists)         none
   set pe(xuser_lists)        none
   set pe(start_proc_args)    "$el_base_path/startmpi.sh \$pe_hostfile" 
   set pe(stop_proc_args)     "$el_base_path/stopmpi.sh" 
   set pe(allocation_rule)    "\$round_robin"
   set pe(control_slaves)     TRUE
   set pe(job_is_first_task)  FALSE
   add_pe tight pe

   set pe(slots)              1000
   set pe(user_lists)         none
   set pe(xuser_lists)        none
   set pe(allocation_rule)    "\$round_robin"
   set pe(control_slaves)     FALSE
   set pe(job_is_first_task)  FALSE
   add_pe loose pe

   # create a queue
   set queue_conf(load_thresholds) "np_load_avg=11"
   set queue_conf(slots) 10
   set queue_conf(rerun) "true"
   set queue_conf(h_rt) "00:00:30"
   add_queue tight.q "@allhosts" queue_conf

   # create a queue
   set queue_conf(load_thresholds) "np_load_avg=11"
   set queue_conf(slots) 10
   set queue_conf(rerun) "true"
   set queue_conf(h_rt) "00:00:30"
   add_queue loose.q "@allhosts" queue_conf

   # assign queue to tight pe 
   assign_queues_with_pe_object tight.q "" tight

   # assign queue to loose pe 
   assign_queues_with_pe_object loose.q "" loose

   # change global config 
   get_config org_global_conf
   set global_conf(load_report_time) "00:00:04"
   set global_conf(max_unheard) "00:00:15"
   set global_conf(qmaster_params) "ENABLE_ENFORCE_MASTER_LIMIT=true,ENABLE_FORCED_QDEL_IF_UNKNOWN=true"
   set global_conf(reporting_params) "accounting_flush_time=00:00:00"
   set_config_and_propagate global_conf

   # change schedd config
   set sched_conf(params) "DURATION_OFFSET=00:00:05"
   set_schedd_config sched_conf 
}

# 100) delete remaining jobs if there are some
# 101) wait for end of all jobs
# 102) remove the pe<->queue assignment
# 103) delete the queue
# 104) reset the config
proc enforce_limits_cleanup {} {
   global ts_config
   global org_global_conf

   # trigger and wait for job termination
   delete_all_jobs
   wait_for_end_of_all_jobs 60

   # unassign tight pe
   unassign_queues_with_pe_object tight
   del_pe tight
   del_queue tight.q "" 0 1

   # unassign loose pe
   unassign_queues_with_pe_object loose 
   del_pe loose 
   del_queue loose.q "" 0 1

   # reset global config
   reset_config_and_propagate org_global_conf

   # reset sched config
   reset_schedd_config
}

# 50) submit a sleeper job
#    - PE with N slots
#    - master queue has to be defined
#    - "qrsh -inherit" job which spawns pe_tasks and then waits
#    - each pe task should sleep 60 seconds
# 51) Wait till all tasks are running
# 52) Wait till all tasks (job) are terminated
# 53) Check accounting entry that job run only a bit more than 30 sec and not 60 sec
proc enforce_limits_tight_execd_limit_enforcement {} {
   global ts_config CHECK_USER
   global CHECK_ACT_LEVEL
   global tight_slots
   global tight_masterq 
   global tight_master_node
   global tight_slaveq
   global tight_slave_node
   global el_base_path

   if {$CHECK_ACT_LEVEL == 0} {
      # submit a job 
      set qsub_params "-pe tight $tight_slots -masterq $tight_masterq $el_base_path/qrexec.sh 60"
      set job_id [ submit_job "$qsub_params" ]

      # wait for start and end 
      wait_for_jobstart $job_id "qrexec.sh" 100 1 1
      wait_for_end_of_transfer $job_id 60
      wait_for_job_end $job_id 120

      # check accounting entry 
      if {[get_qacct $job_id] == 0} {
         set wallclock $qacct_info(ru_wallclock)

         # if the job was running 60 seconds and more that the limit enforcement failed 
         if {$wallclock < 30 || $wallclock > 40} {
            ts_log_severe "wallclock limit seems not to be enfoced in execd for tight PE job"
         }
      } else {
         ts_log_severe "field exit_status is missing in qacct output"
      }
   }
}

# 50) submit a sleeper job
#    - PE with N slots
#    - master queue has to be defined
#    - "qrsh -inherit" job which spawns pe_tasks and then waits
#    - each pe task should sleep 60 seconds
# 51) Wait till all tasks are running
# 52) Terminate all execds where parts of the pe jobs are running
# 53) Wait till all tasks (job) is terminated
# 54) Check that the job has been terminated before the normal runtime ended 
proc enforce_limits_tight_qmaster_limit_enforcement_all_queue {} {
   global ts_config CHECK_USER
   global CHECK_ACT_LEVEL
   global tight_slots
   global tight_masterq 
   global tight_master_node
   global tight_slaveq
   global tight_slave_node
   global el_base_path

   if {$CHECK_ACT_LEVEL == 0} {
      # submit the pe job
      set qsub_params "-pe tight $tight_slots -masterq $tight_masterq $el_base_path/qrexec.sh 180"
      set job_id [ submit_job "$qsub_params" ]

      wait_for_jobstart $job_id "qrexec.sh" 100 1 1
      wait_for_end_of_transfer $job_id 60
      set start [clock seconds]

      # shutdown all execds
      set all_exec_hosts $ts_config(execd_nodes)
      soft_execd_shutdown $all_exec_hosts
      set end_shutdown [clock seconds]

      # wait for termination of job
      wait_for_job_end $job_id 240 
      set end [clock seconds]

      # startup all execds
      set all_exec_hosts $ts_config(execd_nodes)
      foreach host $all_exec_hosts {
         startup_execd $host
      }

      # runtime limit for the job is 30 seconds
      # DURATION_OFFSET is 5 seconds
      # so the shutdown should be triggered after 35 seconds
      # but we have to add the time till the job leaves the system until it can't be seen by by qstat -j
      # so we give it 70 seconds (plus the time for shutting down the execds)
      set start_shutdown [expr $end_shutdown - $start]
      set start_end [expr $end - $start]
      if {$start_end > [expr 70 + $start_shutdown]} {
         ts_log_severe "runtime should be in the range of 35-70 but it is $start_end (start_shutdown = $start_shutdown)"
      }
   }
}

# 50) submit a sleeper job
#    - PE with N slots
#    - master queue has to be defined
#    - "qrsh -inherit" job which spawns pe_tasks and then waits
#    - each pe task should sleep 60 seconds
# 51) Wait till all tasks are running
# 52) Terminate execution host where master task is running
# 53) Wait till all tasks (job) is terminated
# 54) Check that job was terminated before the regular job runtime ended
proc enforce_limits_tight_qmaster_limit_enforcement_master_queue {} {
   global ts_config CHECK_USER
   global CHECK_ACT_LEVEL
   global tight_slots
   global tight_masterq 
   global tight_master_node
   global tight_slaveq
   global tight_slave_node
   global el_base_path

   if {$CHECK_ACT_LEVEL == 0} {
      # submit the pe job
      set qsub_params "-pe tight $tight_slots -masterq $tight_masterq $el_base_path/qrexec.sh 180"
      set job_id [ submit_job "$qsub_params" ]

      wait_for_jobstart $job_id "qrexec.sh" 100 1 1
      wait_for_end_of_transfer $job_id 60
      set start [clock seconds]

      # shutdown master execds
      soft_execd_shutdown $tight_master_node 
      set end_shutdown [clock seconds]

      # wait for termination of job
      wait_for_job_end $job_id 240 
      set end [clock seconds]

      # startup master 
      startup_execd $tight_master_node

      # runtime limit for the job is 30 seconds
      # DURATION_OFFSET is 5 seconds
      # so the shutdown should be triggered after 35 seconds
      # but we have to add the time till the job leaves the system until it can't be seen by by qstat -j
      # so we give it 70 seconds
      set start_shutdown [expr $end_shutdown - $start]
      set start_end [expr $end - $start]
      if {$start_end > [expr 70 + $start_shutdown]} {
         ts_log_severe "runtime should be in the range of 35-70 but it is $start_end (start_shutdown = $start_shutdown)"
      }
   }
}

# 50) submit a sleeper job
#    - PE with N slots
#    - master queue has to be defined
#    - "qrsh -inherit" job which spawns pe_tasks and then waits
#    - each pe task should sleep 60 seconds
# 51) Wait till all tasks are running
# 52) Terminate execution host where one slave task is running
# 52) Wait till all tasks (job) is terminated
# 53) Check that job was terminated before the regular job runtime ended
proc enforce_limits_tight_qmaster_limit_enforcement_slave_queue {} {
   global ts_config CHECK_USER
   global CHECK_ACT_LEVEL
   global tight_slots
   global tight_masterq 
   global tight_master_node
   global tight_slaveq
   global tight_slave_node
   global el_base_path

   if {$CHECK_ACT_LEVEL == 0} {
      # submit the pe job
      set qsub_params "-pe tight $tight_slots -masterq $tight_masterq $el_base_path/qrexec.sh 180"
      set job_id [ submit_job "$qsub_params" ]

      wait_for_jobstart $job_id "qrexec.sh" 100 1 1
      wait_for_end_of_transfer $job_id 60
 
      set start [clock seconds]

      # shutdown master execds
      soft_execd_shutdown $tight_slave_node 
      set end_shutdown [clock seconds]

      # wait for termination of job
      wait_for_job_end $job_id 240 
      set end [clock seconds]

      # startup master 
      startup_execd $tight_slave_node

      # runtime limit for the job is 30 seconds
      # DURATION_OFFSET is 5 seconds
      # so the shutdown should be triggered after 35 seconds
      # but we have to add the time till the job leaves the system until it can't be seen by by qstat -j
      # so we give it 70 seconds
      set start_shutdown [expr $end_shutdown - $start]
      set start_end [expr $end - $start]
      if {$start_end > [expr 70 + $start_shutdown]} {
         ts_log_severe "runtime should be in the range of 35-70 but it is $start_end (start_shutdown = $start_shutdown)"
      }
   }
}

# 50) submit a sleeper job
#    - PE with N slots (loose integration)
#    - master queue has to be defined
#    - "qrsh -inherit" job which spawns pe_tasks and then waits
#    - each pe task should sleep 60 seconds
# 51) Wait till all tasks are running
# 52) Terminate all execds where parts of the pe jobs are running
# 52) Wait till all tasks (job) is terminated
# 53) Check that the job has been terminated before the normal runtime ended 
proc enforce_limits_loose_qmaster_limit_enforcement_all_queue {} {
   global ts_config CHECK_USER
   global CHECK_ACT_LEVEL
   global loose_slots
   global loose_masterq 
   global loose_master_node
   global loose_slaveq
   global loose_slave_node
   global el_base_path

   if {$CHECK_ACT_LEVEL == 0} {
      # submit the pe job
      set qsub_params "-pe loose $loose_slots -masterq $loose_masterq $ts_config(product_root)/examples/jobs/sleeper.sh 180"
      set job_id [ submit_job "$qsub_params" ]

      wait_for_jobstart $job_id "Sleeper" 100 1 1
      wait_for_end_of_transfer $job_id 60

      set start [clock seconds]

      # shutdown all execds
      set all_exec_hosts $ts_config(execd_nodes)
      soft_execd_shutdown $all_exec_hosts
      set end_shutdown [clock seconds]

      # wait for termination of job
      wait_for_job_end $job_id 240 
      set end [clock seconds]

      # startup all execds
      set all_exec_hosts $ts_config(execd_nodes)
      foreach host $all_exec_hosts {
         startup_execd $host
      }

      # runtime limit for the job is 30 seconds
      # DURATION_OFFSET is 5 seconds
      # so the shutdown should be triggered after 35 seconds
      # but we have to add the time till the job leaves the system until it can't be seen by by qstat -j
      # so we give it 70 seconds
      set start_shutdown [expr $end_shutdown - $start]
      set start_end [expr $end - $start]
      if {$start_end > [expr 70 + $start_shutdown]} {
         ts_log_severe "runtime should be in the range of 35-70 but it is $start_end (start_shutdown = $start_shutdown"
      }
   }
}

# 50) submit a sleeper job
#    - PE with N slots
#    - master queue has to be defined
#    - "qrsh -inherit" job which spawns pe_tasks and then waits
#    - each pe task should sleep 60 seconds
# 51) Wait till all tasks are running
# 52) Terminate execution host where master task is running
# 53) Start execution host again 
# 54) Wait till all tasks (job) is terminated
# 55) Check that job was terminated before the regular job runtime ended
# 56) Make sure that job was terminated by execd
proc enforce_limits_tight_execd_limit_enforcement_after_stop_start {} {
   global ts_config CHECK_USER
   global CHECK_ACT_LEVEL
   global tight_slots
   global tight_masterq 
   global tight_master_node
   global tight_slaveq
   global tight_slave_node
   global el_base_path

   if {$CHECK_ACT_LEVEL == 0} {
      # submit the pe job
      set qsub_params "-pe tight $tight_slots -masterq $tight_masterq $el_base_path/qrexec.sh 90"
      set job_id [ submit_job "$qsub_params" ]

      wait_for_jobstart $job_id "qrexec.sh" 100 1 1
      wait_for_end_of_transfer $job_id 60

      set start [clock seconds]

      # shutdown master execds
      # TODO: Test runs not for 62_BRANCH, and shutdown_system daemon does not shutdown execd fast enough
      #       AND execd reconnect might take up to 60 seconds. The wait_for_unknown_load 15 call is not guaranteed
      soft_execd_shutdown $tight_master_node 
      wait_for_unknown_load 15 $tight_masterq

      # startup master 
      startup_execd $tight_master_node

      # wait for termination of job
      wait_for_job_end $job_id 100 
      set end [clock seconds]

      # so we give it 70 seconds plus 15 seconds for the execd startup
      set start_end [expr $end - $start]
      if {$start_end > 85} {
         ts_log_severe "runtime should be in the range of 35-85 but it is $start_end"
      }

      # check accounting entry 
      if {[get_qacct $job_id] == 0} {
         set task [lindex $qacct_info(failed) [expr $tight_slots - 1]]
         set failed [lindex $task 0]

         if {$failed != 100} {
            ts_log_severe "job $job_id died trough limit exceeding executed by the execution deamon. Therefore it should end with failed=100 but it failed with $failed"
         }
      } else {
         ts_log_severe "didn't find accounting entry of job $job_id"
      }
   }
}

# 50) submit a sleeper job
#    - PE with N slots
#    - master queue has to be defined
#    - "qrsh -inherit" job which spawns pe_tasks and then waits
#    - each pe task should sleep 60 seconds
# 51) Wait till all tasks are running
# 52) Terminate all execds where parts of the pe jobs are running
# 53) Start the master execd again
# 54) Wait till all tasks (job) is terminated
# 55) Check that the job has been terminated before the normal runtime ended 
proc enforce_limits_tight_qmaster_limit_enforcement_after_stop_start_master {} {
   global ts_config CHECK_USER
   global CHECK_ACT_LEVEL
   global tight_slots
   global tight_masterq 
   global tight_master_node
   global tight_slaveq
   global tight_slave_node
   global el_base_path


   if {$CHECK_ACT_LEVEL == 0} {
      # submit the pe job
      set qsub_params "-pe tight $tight_slots -masterq $tight_masterq $el_base_path/qrexec.sh 180"
      set job_id [ submit_job "$qsub_params" ]
      wait_for_jobstart $job_id "qrexec.sh" 60 1 1
      wait_for_end_of_transfer $job_id 60
      set start [clock seconds]
  
      # at least one slave task must be running. 5 seconds should be enough
      # so that one slave execd reports one task running 
      after 5000

      # shutdown all execds and startup one again
      set all_exec_hosts $ts_config(execd_nodes)
      soft_execd_shutdown $all_exec_hosts 

      startup_execd $tight_master_node
      set end_shutdown [clock seconds]

      # wait for termination of job
      wait_for_job_end $job_id 240 
      set end [clock seconds]

      # startup all execds
      soft_execd_shutdown $tight_master_node 
      set all_exec_hosts $ts_config(execd_nodes)
      foreach host $all_exec_hosts {
         startup_execd $host
      }

      # runtime limit for the job is 30 seconds
      # DURATION_OFFSET is 5 seconds
      # so the shutdown should be triggered after 35 seconds
      # but we have to add the time till the job leaves the system until it can't be seen by by qstat -j
      # so we give it 70 seconds (plus the time for shutting down the execds)
      set start_shutdown [expr $end_shutdown - $start]
      set start_end [expr $end - $start]
      if {$start_end > [expr 70 + $start_shutdown]} {
         ts_log_severe "runtime should be in the range of 35-70 but it is $start_end (start_shutdown = $start_shutdown)"
      }
   }
}

# 50) submit a sleeper job
#    - PE with N slots
#    - slave queue has to be defined
#    - "qrsh -inherit" job which spawns pe_tasks and then waits
#    - each pe task should sleep 60 seconds
# 51) Wait till all tasks are running
# 52) Terminate all execds where parts of the pe jobs are running
# 53) Start the slave execd again
# 54) Wait till all tasks (job) is terminated
# 55) Check that the job has been terminated before the normal runtime ended 
proc enforce_limits_tight_qmaster_limit_enforcement_after_stop_start_slave {} {
   global ts_config CHECK_USER
   global CHECK_ACT_LEVEL
   global tight_slots
   global tight_masterq 
   global tight_master_node
   global tight_slaveq
   global tight_slave_node
   global el_base_path

   if {$CHECK_ACT_LEVEL == 0} {
      # submit the pe job
      set qsub_params "-pe tight $tight_slots -masterq $tight_masterq $el_base_path/qrexec.sh 180"
      set job_id [ submit_job "$qsub_params" ]
      wait_for_jobstart $job_id "qrexec.sh" 60 1 1
      wait_for_end_of_transfer $job_id 60

      # at least one slave task must be running. 5 seconds should be enough
      # so that one slave execd reports one task running 
      after 5000

      set start [clock seconds]

      # shutdown all execds and startup one again
      set all_exec_hosts $ts_config(execd_nodes)
      soft_execd_shutdown $all_exec_hosts 

      startup_execd $tight_slave_node
      set end_shutdown [clock seconds]

      # wait for termination of job
      wait_for_job_end $job_id 240 
      set end [clock seconds]

      # startup all execds
      soft_execd_shutdown $tight_slave_node

      set all_exec_hosts $ts_config(execd_nodes)
      foreach host $all_exec_hosts {
         startup_execd $host
      }

      # runtime limit for the job is 30 seconds
      # DURATION_OFFSET is 5 seconds
      # so the shutdown should be triggered after 35 seconds
      # but we have to add the time till the job leaves the system 
      # until it can't be seen by by qstat -j
      # so we give it 70 seconds (plus the time for shutting down the execds)
      set start_shutdown [expr $end_shutdown - $start]
      set start_end [expr $end - $start]
      if {$start_end > [expr 70 + $start_shutdown]} {
         ts_log_severe "runtime should be in the range of 35-70 but it is $start_end (start_shutdown = $start_shutdown)"
      }
   }
}



# 50) submit a sleeper job
#    - PE with N slots
#    - master queue has to be defined
#    - "qrsh -inherit" job which spawns pe_tasks and then waits
#    - each pe task should sleep 60 seconds
# 51) Wait till all tasks are running
# 52) Terminate all execds where parts of the pe jobs are running
# 53) Wait till all tasks (job) is terminated
# 54) Check that the job has been terminated before the normal runtime ended 
proc enforce_limits_tight_qmaster_forced_all_queue {} {
   global ts_config CHECK_USER
   global CHECK_ACT_LEVEL
   global tight_slots
   global tight_masterq 
   global tight_master_node
   global tight_slaveq
   global tight_slave_node
   global el_base_path

   if {$CHECK_ACT_LEVEL == 0} {
      # submit the pe job
      set qsub_params "-pe tight $tight_slots -masterq $tight_masterq $el_base_path/qrexec.sh 180"
      set job_id [ submit_job "$qsub_params" ]

      wait_for_jobstart $job_id "qrexec.sh" 100 1 1
      wait_for_end_of_transfer $job_id 60

      set start [clock seconds]

      # shutdown all execds
      set all_exec_hosts $ts_config(execd_nodes)
      soft_execd_shutdown $all_exec_hosts

      set end_shutdown [clock seconds]

      # wait for termination of job
      wait_for_job_end $job_id 240 
      set end [clock seconds]

      # startup all execds
      set all_exec_hosts $ts_config(execd_nodes)
      foreach host $all_exec_hosts {
         startup_execd $host
      }

      # runtime limit for the job is 30 seconds
      # DURATION_OFFSET is 5 seconds
      # so the shutdown should be triggered after 35 seconds
      # but we have to add the time till the job leaves the system until it can't be seen by by qstat -j
      # so we give it 70 seconds (plus the time for shutting down the execds)
      set start_shutdown [expr $end_shutdown - $start]
      set start_end [expr $end - $start]
      if {$start_end > [expr 70 + $start_shutdown]} {
         ts_log_severe "runtime should be in the range of 35-70 but it is $start_end (start_shutdown = $start_shutdown)"
      }

      # check accounting entry  
      if {[get_qacct $job_id] == 0} { 
         set task [lindex $qacct_info(failed) 0]
         set failed [lindex $task 0]

         if {$failed != 37} {
            ts_log_severe "job died trough limit exceeding executed by the master deamon. Therefore it should end with failed=37 but it failed with $failed"
         }
      }

   }
}

# 50) submit a batch sleeper job
# 51) Wait till job is running
# 52) Terminate execd
# 53) Wait till job is terminated
# 54) Check that the job has been terminated before the normal runtime ended 
proc enforce_limits_batch_qmaster_limit_enforcement_all_queue {} {
   global ts_config CHECK_USER
   global CHECK_ACT_LEVEL
   global tight_slots
   global tight_masterq 
   global tight_master_node
   global tight_slaveq
   global tight_slave_node
   global el_base_path

   if {$CHECK_ACT_LEVEL == 0} {
      # submit the pe job
      set qsub_params "-q $tight_masterq $ts_config(product_root)/examples/jobs/sleeper.sh 180"
      set job_id [ submit_job "$qsub_params" ]

      wait_for_jobstart $job_id "Sleeper" 100 1 1
      wait_for_end_of_transfer $job_id 60

      set start [clock seconds]

      # shutdown all execds
      soft_execd_shutdown $tight_master_node
      set end_shutdown [clock seconds]

      # wait for termination of job
      wait_for_job_end $job_id 240 
      set end [clock seconds]

      # startup all execds
      startup_execd $tight_master_node

      # runtime limit for the job is 30 seconds
      # DURATION_OFFSET is 5 seconds
      # so the shutdown should be triggered after 35 seconds
      # but we have to add the time till the job leaves the system until it can't be seen by by qstat -j
      # so we give it 70 seconds (plus the time for shutting down the execds)
      set start_shutdown [expr $end_shutdown - $start]
      set start_end [expr $end - $start]
      if {$start_end > [expr 70 + $start_shutdown]} {
         ts_log_severe "runtime should be in the range of 35-70 but it is $start_end (start_shutdown = $start_shutdown)"
      }

      # check accounting entry  
      if {[get_qacct $job_id] == 0} { 
         set task [lindex $qacct_info(failed) 0]
         set failed [lindex $task 0]

         if {$failed != 37} {
            ts_log_severe "job died trough limit exceeding executed by the master deamon. Therefore it should end with failed=37 but it failed with $failed"
         }
      }

   }
}
