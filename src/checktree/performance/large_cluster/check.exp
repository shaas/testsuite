#!/vol2/TCL_TK/glinux/bin/expect
#___INFO__MARK_BEGIN__
##########################################################################
#
#  The Contents of this file are made available subject to the terms of
#  the Sun Industry Standards Source License Version 1.2
#
#  Sun Microsystems Inc., March, 2001
#
#
#  Sun Industry Standards Source License Version 1.2
#  =================================================
#  The contents of this file are subject to the Sun Industry Standards
#  Source License Version 1.2 (the "License"); You may not use this file
#  except in compliance with the License. You may obtain a copy of the
#  License at http://gridengine.sunsource.net/Gridengine_SISSL_license.html
#
#  Software provided under this License is provided on an "AS IS" basis,
#  WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING,
#  WITHOUT LIMITATION, WARRANTIES THAT THE SOFTWARE IS FREE OF DEFECTS,
#  MERCHANTABLE, FIT FOR A PARTICULAR PURPOSE, OR NON-INFRINGING.
#  See the License for the specific provisions governing your rights and
#  obligations concerning the Software.
#
#  The Initial Developer of the Original Code is: Sun Microsystems, Inc.
#
#  Copyright: 2001 by Sun Microsystems, Inc.
#
#  All Rights Reserved.
#
##########################################################################
#___INFO__MARK_END__

# define global variable in this namespace
global check_name 
global check_category
global check_description 
global check_needs
global check_functions 
global check_errno 
global check_errstr 
global check_highest_level
global check_init_level_procedure
global check_root_access_needs
global env

set check_root_access_needs "yes"

# some global settings
global CHECK_CORE_EXECD
global LARGE_CLUSTER_HOST_PREFIX 
global LARGE_CLUSTER_HOSTS_PER_HOST 
global LARGE_CLUSTER_QUEUES_PER_HOST 
global LARGE_CLUSTER_SLOTS_PER_QUEUE
global LARGE_CLUSTER_JOB_SIZES
global LARGE_CLUSTER_JOB_DURATION
global LARGE_CLUSTER_POLICIES_PROJECTS 
global LARGE_CLUSTER_POLICIES_JOBS

set LARGE_CLUSTER_HOST_PREFIX       "lchost_"
set LARGE_CLUSTER_HOSTS_PER_HOST    100
set LARGE_CLUSTER_QUEUES_PER_HOST   2
set LARGE_CLUSTER_SLOTS_PER_QUEUE   1
set LARGE_CLUSTER_JOB_SIZES         "500 1000 1500 2000 25*1-100 10*1-300 7*1-500 4*1-1000 4*1-2000:2"
set LARGE_CLUSTER_JOB_DURATION      60
set LARGE_CLUSTER_POLICIES_PROJECTS "100 200 300 400 500 600 700 800 900 1000"
set LARGE_CLUSTER_POLICIES_JOBS     1000

# define a level initialization procedure:
set check_init_level_procedure "large_cluster_init_level"

# define test's name and run level descriptions
set check_name            "large_cluster"
set check_category        "PERFORMANCE"
set check_highest_level   [expr ( [llength $CHECK_CORE_EXECD] - 2 + 300 ) ]
for {set i 300} {$i <= $check_highest_level} {incr i} {
   set check_description($i) "check performance with [expr ( $i - 300 + 1 ) * $LARGE_CLUSTER_HOSTS_PER_HOST] queues"
}

#debug settings
#set LARGE_CLUSTER_HOSTS_PER_HOST    10
#set LARGE_CLUSTER_JOB_SIZES         "40 5*1-20:2"
#set LARGE_CLUSTER_JOB_DURATION      20
#set LARGE_CLUSTER_POLICIES_PROJECTS "10 20"
#set LARGE_CLUSTER_POLICIES_JOBS     100
#set LARGE_CLUSTER_SLOTS_PER_QUEUE   2
#set check_highest_level   301

# define test's dependencies
set check_needs           "init_core_system" 

# define test's procedure order
set check_functions ""
lappend check_functions "large_cluster_setup"
lappend check_functions "large_cluster_jobs"
lappend check_functions "large_cluster_throughput"
lappend check_functions "large_cluster_usersort"
lappend check_functions "large_cluster_sharetree"
lappend check_functions "large_cluster_global"
lappend check_functions "large_cluster_cleanup"


proc large_cluster_init_level {} {
   global CHECK_OUTPUT CHECK_ACT_LEVEL CHECK_CORE_EXECD
   global LARGE_CLUSTER_JOB_SIZES LARGE_CLUSTER_POLICIES_PROJECTS
   global real_hosts check_highest_level

   # here we should check whether the setup of hostname resolving is
   # done correctly on all involved hosts

   if { $CHECK_ACT_LEVEL >= 300 && $CHECK_ACT_LEVEL <= $check_highest_level } {
      set real_hosts [lrange $CHECK_CORE_EXECD 1 [expr 1 + $CHECK_ACT_LEVEL - 300]]
      return 0 
   }

   return -1;
}

# -------- local test procedures -----------------------------------------------

proc large_cluster_disable_queues {} {
   global CHECK_OUTPUT CHECK_PRODUCT_ROOT CHECK_ARCH
   global queue_list

   puts $CHECK_OUTPUT "disabling all queues"
   foreach queue $queue_list {
      catch {exec $CHECK_PRODUCT_ROOT/bin/$CHECK_ARCH/qmod -d $queue}
      puts -nonewline $CHECK_OUTPUT "." ; flush $CHECK_OUTPUT  
   }
   puts $CHECK_OUTPUT ""
}

proc large_cluster_enable_queues {} {
   global CHECK_OUTPUT CHECK_PRODUCT_ROOT CHECK_ARCH
   global queue_list

   puts $CHECK_OUTPUT "enabling all queues"
   foreach queue $queue_list {
      catch {exec $CHECK_PRODUCT_ROOT/bin/$CHECK_ARCH/qmod -e $queue}
      puts -nonewline $CHECK_OUTPUT "." ; flush $CHECK_OUTPUT  
   }
   puts $CHECK_OUTPUT ""
}

proc large_cluster_parse_cpu {s_cpu} {
   set l_cpu [split $s_cpu ":"]
   set cpu 0

   while {[llength $l_cpu] > 0} {
      scan [lindex $l_cpu 0] "%02d" part
      
      switch [llength $l_cpu] {
         1 {
            incr cpu $part
         }
         2 {
            incr cpu [expr $part * 60]
         }
         3 {
            incr cpu [expr $part * 3600]
         }
         default {
            add_proc_error large_cluster_parse_cpu -1 "cannot parse cpu time $s_cpu"
         }
      }

      set l_cpu [lreplace $l_cpu 0 0]
   }

   return $cpu
}

proc large_cluster_submit_a_job {host job_list_var id_list_var sids_var hosts_var} {
   global CHECK_OUTPUT CHECK_PRODUCT_ROOT

   upvar $job_list_var job_list
   upvar $id_list_var  id_list
   upvar $sids_var     sids
   upvar $hosts_var    hosts

   if {[llength $job_list] > 0} {
      set job [lindex $job_list 0]
      set job_list [lrange $job_list 1 end]
      set args [lindex $job 0]
      set user [lindex $job 1]
      
      set sid [open_remote_spawn_process $host $user "$CHECK_PRODUCT_ROOT/bin/[resolve_arch $host]/qsub" $args]

      set id [lindex $sid 1]
      lappend id_list $id
      set sids($id) $sid
      set hosts($id) $host

      puts $CHECK_OUTPUT "user $user submitted job \"$args\" on host $host"

      return 1
   } else {
      return 0
   }
}

proc large_cluster_submit_jobs {size {users ""} {projects ""}} {
   global CHECK_OUTPUT LARGE_CLUSTER_JOB_DURATION CHECK_PRODUCT_ROOT CHECK_ARCH CHECK_USER CHECK_HOST
   global CHECK_PRODUCT_TYPE CHECK_CORE_EXECD
   
   # parse array job info
   set l_size [split $size "*"]
   set num_jobs [lindex $l_size 0]
   if {[llength $l_size] > 1} {
      set array_opt [lindex $l_size 1]
   } else {
      set array_opt ""
   }

   # check users and projects
   if {[llength $users] == 0} {
      set users $CHECK_USER
   }
   if {[llength $projects] == 0} {
      set projects mytestproject
   }

   
   if {$array_opt != ""} {
      set args "-t $array_opt "
   } else {
      set args ""
   }

   append args "-o /dev/null -j y $CHECK_PRODUCT_ROOT/examples/jobs/sleeper.sh"

   # submit jobs
   puts $CHECK_OUTPUT "submitting $size jobs with a duration of $LARGE_CLUSTER_JOB_DURATION s each"

   # build a list with jobs to submit
   set jobs_submitted 0
   set job_list {}
   set finished 0
   while {$jobs_submitted < $num_jobs} {
      foreach project $projects {
         if {[string compare $CHECK_PRODUCT_TYPE sgeee] == 0} {
            set prj_args "-P $project"
         } else {
            set prj_args ""
         }
         foreach user $users {
            set runtime [expr $LARGE_CLUSTER_JOB_DURATION -5 + $jobs_submitted % 11]
            # store job in list
            lappend job_list [list "$prj_args $args $runtime" "$user"]
            #submit_job "$prj_args $args $runtime" 1 300 $CHECK_HOST $user
            incr jobs_submitted
            if {$jobs_submitted >= $num_jobs} {
               set finished 1
               break
            }
         }
         if {$finished == 1} {
            break
         }
      }
   }

   set submit_host_list [lrange $CHECK_CORE_EXECD 1 10]

   # submit first bunch of jobs
   # keep a list of expect spawn id's for expect calls
   # keep arrays: 
   #    - sids(id): the spawn ids for close_spawn_process
   #    - hosts(id): the host for an id - can be reused when qsub finishes
   set id_list {}
   foreach host $submit_host_list {
      if {[large_cluster_submit_a_job $host job_list id_list sids hosts] == 0} {
         break
      }
   }

   # process all jobs
   set finished 0
   while {$finished == 0} {
      set timeout 60
      expect {
         full_buffer {
            add_proc_error large_cluster_submit_jobs -1 "buffer overflow please increment CHECK_EXPECT_MATCH_MAX_BUFFER value"
         }
         timeout {
            add_proc_error large_cluster_submit_jobs -2 "timeout waiting for submit to finish"
            set finished 1
         }
         -i $id_list -- "has been submitted" {
            # close old connection
            set id $expect_out(spawn_id)
            close_spawn_process $sids($id)
            unset sids($id)
            set index [lsearch -exact $id_list $id]
            set id_list [lreplace $id_list $index $index]

            # submit next
            # if no jobs left to submit and id_list empty, we are finished
            set host $hosts($id)
            unset hosts($id)
            if {[large_cluster_submit_a_job $host job_list id_list sids hosts] == 0} {
               if {[llength $id_list] == 0} {
                  set finished 1
               }
            }
         }
         -i $id_list -- default {
            add_proc_error large_cluster_submit_jobs -2 "submit failed"
            # close old connection
            set id $expect_out(spawn_id)
            close_spawn_process $sids($id)
            unset sids($id)
            unset hosts($id)
            set index [lsearch -exact $id_list $id]
            set id_list [lreplace $id_list $index $index]
         }
      }
   }
}

proc large_cluster_init_monitoring {} {
   global ts_config
   global CHECK_HOST CHECK_SECOND_FOREIGN_SYSTEM_USER
   global CHECK_PRODUCT_ROOT
   global qmaster_spool_dir

   # remove accounting file - we use it to compute utilization
   file delete "$CHECK_PRODUCT_ROOT/$ts_config(cell)/common/accounting"

   # spawn a tail -f to schedd messages file and skip first (old) lines
   # we use the second configured test user to avoid having two open_remote_spawn
   # processes with same userid and same host
   set messages_name "$qmaster_spool_dir/schedd/messages"
   set tail_id [open_remote_spawn_process $CHECK_HOST $CHECK_SECOND_FOREIGN_SYSTEM_USER /usr/bin/tail "-f $messages_name"]
   set skipping 1
   set sp_id [ lindex $tail_id 1 ] 

   while {$skipping == 1} {
      set timeout 5
      expect {
         -i $sp_id full_buffer {
            add_proc_error "large_cluster_test" -1 "buffer overflow please increment CHECK_EXPECT_MATCH_MAX_BUFFER value" 
         }
         -i $sp_id timeout {
            set skipping 0
         }
         -i $sp_id "*\n" {
         }
      }
   }

   return $tail_id
}

proc large_cluster_monitoring {tail_id first_sched_var total_sched_var index} {
   global CHECK_OUTPUT 
   global qmaster_spool_dir

   upvar $first_sched_var first_sched
   upvar $total_sched_var total_sched

   set done 0
   set first 1
   set sp_id [ lindex $tail_id 1 ] 
   while {$done == 0} {
      set timeout 10
      expect {
         -i $sp_id full_buffer {
            close_spawn_process $tail_id
            add_proc_error "large_cluster_test" -1 "buffer overflow please increment CHECK_EXPECT_MATCH_MAX_BUFFER value"
            continue
         }
         -i $sp_id timeout {
            puts -nonewline $CHECK_OUTPUT "." ; flush $CHECK_OUTPUT
         }
         -i $sp_id "^*scheduled in*\n" {
            # split at \n
            set lines [split $expect_out(0,string) "\n"]
            foreach line $lines {
               set file_fields [split $line "|"]
               set sched_info [lindex $file_fields 4]
               if {[string length $sched_info] > 0 && [llength $sched_info] > 10} {
                  set time [lindex $sched_info 2]
                  set fast [lindex $sched_info 4]
                  set complex [lindex $sched_info 6]
                  set orders [lindex $sched_info 8]

                  if {$first == 1} {
                     if {[expr $fast + $complex] > 0} {
                        set first_sched(time,$index)    $time
                        set first_sched(fast,$index)    $fast
                        set first_sched(complex,$index) $complex
                        set first_sched(orders,$index)  $orders

                        set total_sched(count,$index)   1
                        set total_sched(time,$index)    $time
                        set total_sched(fast,$index)    $fast
                        set total_sched(complex,$index) $complex
                        set total_sched(orders,$index)  $orders

                        set first 0
                     }
                  } else {
                     incr total_sched(count,$index)   1
                     set total_sched(time,$index)    [expr $total_sched(time,$index) + $time]
                     incr total_sched(fast,$index)    $fast
                     incr total_sched(complex,$index) $complex
                     incr total_sched(orders,$index)  $orders
                  }
               }
            }
         }
      }

      # until no jobs are left in the cluster
      set job_count 0
      catch {set job_count [llength [glob -directory $qmaster_spool_dir/jobs "*/*/*"]]}
      if {$job_count == 0} {
         set done 1
      }
   }

   send -i $sp_id "\003";# send CTRL-C to terminate tail -f
   close_spawn_process $tail_id

   puts $CHECK_OUTPUT ""
}

proc large_cluster_job_runtime {} {
   global ts_config
   global CHECK_OUTPUT CHECK_PRODUCT_ROOT 

   # parse accounting file and sum up the jobs runtime
   set accounting_file_name "$CHECK_PRODUCT_ROOT/$ts_config(cell)/common/accounting"
   set runtime 0

   if [file exists $accounting_file_name] {
      set f [open $accounting_file_name r]
      while {[gets $f line] > 0} {
         # skip comments
         if {[string compare -length 1 $line "#"] == 0} {
            continue
         }

         # parse line, sum up runtime
         set temp [split $line ":"]
         incr runtime [expr [lindex $temp 10] - [lindex $temp 9]]
      }
   }

   return $runtime
}

proc large_cluster_statistics {time_var cpu_var mem_var jr_var index} {
   global pids

   upvar $time_var time
   upvar $cpu_var  cpu
   upvar $mem_var  mem
   upvar $jr_var   job_runtime
   
   get_ps_info

   set time($index) [clock seconds]
   set cpu(qmaster,$index) [large_cluster_parse_cpu $ps_info($pids(qmaster),time)]
   set cpu(schedd,$index)  [large_cluster_parse_cpu $ps_info($pids(schedd),time)]
   set mem(qmaster,$index) $ps_info($pids(qmaster),vsz)
   set mem(schedd,$index)  $ps_info($pids(schedd),vsz)
   set job_runtime($index) [large_cluster_job_runtime]
}

proc large_cluster_write_file {type target content {mode a}} {
   global CHECK_PROTOCOL_DIR

   set f [open "$CHECK_PROTOCOL_DIR/large_cluster_${type}_${target}.txt" $mode]
   puts $f $content
   close $f
}

proc large_cluster_write_statistics {type index start_time end_time start_cpu end_cpu mem first_sched total_sched job_runtime} {
   global CHECK_OUTPUT CHECK_ACT_LEVEL LARGE_CLUSTER_HOSTS_PER_HOST LARGE_CLUSTER_QUEUES_PER_HOST LARGE_CLUSTER_SLOTS_PER_QUEUE
   global check_highest_level

   upvar $start_time st
   upvar $end_time et
   upvar $start_cpu sc
   upvar $end_cpu ec
   upvar $mem     m
   upvar $first_sched fs
   upvar $total_sched ts
   upvar $job_runtime jr

   set slots [expr ($CHECK_ACT_LEVEL - 300 + 1) * $LARGE_CLUSTER_HOSTS_PER_HOST * $LARGE_CLUSTER_QUEUES_PER_HOST * $LARGE_CLUSTER_SLOTS_PER_QUEUE]

   set line_prefix "[expr ($CHECK_ACT_LEVEL - 300 + 1) * $LARGE_CLUSTER_HOSTS_PER_HOST]"

   # runtime
   set line $line_prefix
   foreach i $index {
      append line "\t[expr $et($i) - $st($i)]"
   }
   large_cluster_write_file $type runtime $line

   # utilization
   set line $line_prefix
   foreach i $index {
      set runtime [expr $et($i) - $st($i)]
      set jobtime $jr($i)
      puts $CHECK_OUTPUT "runtime = $runtime, jobtime = $jobtime, slots = $slots"
      if {$jobtime > 0} {
         set utilization [expr $jobtime / $slots * 100 / $runtime]
      } else {
         set utilization 0
      }   
      append line "\t$utilization"
   }
   large_cluster_write_file $type utilization $line

   # cpu qmaster
   set line $line_prefix
   foreach i $index {
      append line "\t[expr $ec(qmaster,$i) - $sc(qmaster,$i)]"
   }
   large_cluster_write_file $type cpu_qmaster $line

   # cpu schedd
   set line $line_prefix
   foreach i $index {
      append line "\t[expr $ec(schedd,$i) - $sc(schedd,$i)]"
   }
   large_cluster_write_file $type cpu_schedd $line

   # first schedule
   set line $line_prefix
   foreach i $index {
      append line "\t$fs(time,$i)"
   }
   large_cluster_write_file $type first_jobs $line

   # avg jobs
   set line $line_prefix
   foreach i $index {
      append line "\t[expr $ts(time,$i) * 1000.0 / $ts(fast,$i)]"
   }
   large_cluster_write_file $type avg_jobs $line

   # avg orders
   set line $line_prefix
   foreach i $index {
      append line "\t[expr $ts(time,$i) * 1000.0 / $ts(orders,$i)]"
   }
   large_cluster_write_file $type avg_orders $line
}

proc large_cluster_throughput {} {  
   global CHECK_OUTPUT CHECK_PRODUCT_ROOT CHECK_ARCH

   # configure throughput cluster
   # disable load adjustment
   get_schedd_config schedd_config
   set new_schedd_config(job_load_adjustments)        "none"
   set new_schedd_config(load_adjustment_decay_time)  "0:0:0"
   set new_schedd_config(schedd_job_info)             "false"
   set_schedd_config new_schedd_config

   # disable load thresholds
   if {[info exists change_array]} {
      unset change_array
   }
   set change_array(load_thresholds) "NONE"
   catch { exec "$CHECK_PRODUCT_ROOT/bin/$CHECK_ARCH/qconf" "-sql" } result
   if { [string first "no queue defined" $result] >= 0 } {
      puts $CHECK_OUTPUT "no queue defined"
   } else {
      foreach elem $result {
         set_queue $elem change_array
      }
   }

   # run test
   large_cluster_process_jobs throughput

   # restore configuration
   set_schedd_config schedd_config

   # enable load thresholds
   if {[info exists change_array]} {
      unset change_array
   }
   set change_array(load_thresholds) "np_load_avg=10.0"
   catch { exec "$CHECK_PRODUCT_ROOT/bin/$CHECK_ARCH/qconf" "-sql" } result
   if { [string first "no queue defined" $result] >= 0 } {
      puts $CHECK_OUTPUT "no queue defined"
   } else {
      foreach elem $result {
         set_queue $elem change_array
      }
   }

   set_error 0 "ok"
}

proc large_cluster_usersort {} {  
   global CHECK_OUTPUT CHECK_PRODUCT_ROOT CHECK_ARCH CHECK_PRODUCT_TYPE

   if { [ string compare $CHECK_PRODUCT_TYPE "sgeee" ] == 0 } {
      set_error -3 "not available for sgeee system"
      return
   }

   # configure usersort cluster
   # disable load adjustment
   get_schedd_config schedd_config
   set new_schedd_config(user_sort)        "true"
   set_schedd_config new_schedd_config

   # run test
   large_cluster_process_jobs usersort

   # restore configuration
   set_schedd_config schedd_config

   set_error 0 "ok"
}

proc large_cluster_jobs {} {
   # run test in default environment
   large_cluster_process_jobs job

   set_error 0 "ok"
}

proc large_cluster_size {size} {
   # format is either <jobs> or <jobs>*<range>:<step>
   set split1 [split $size "*"]

   # format 1
   if {[llength $split1] == 1} {
      return $size
   }

   # format 2
   set jobs [lindex $split1 0]

   set split2 [split [lindex $split1 1] ":"]
   if {[llength $split2] == 2} {
      set step [lindex $split2 1]
   } else {
      set step 1
   }

   set split3 [split [lindex $split2 0] "-"]
   if {[llength $split3] == 2} {
      set start [lindex $split3 0]
      set end   [lindex $split3 1]
      if {$start > $end} {
         add_proc_error large_cluster_size -1 "illegal range in task_id_range $size"
         return -1
      }
   } else {
      set start $split3
      set end   $split3
   }

   return [expr $jobs * ((($end - $start) / $step) + 1)]
}

proc large_cluster_process_jobs {type} {
   global CHECK_OUTPUT CHECK_PRODUCT_ROOT CHECK_ARCH CHECK_ACT_LEVEL CHECK_HOST
   global CHECK_USER CHECK_FIRST_FOREIGN_SYSTEM_USER
   global LARGE_CLUSTER_HOSTS_PER_HOST LARGE_CLUSTER_QUEUES_PER_HOST LARGE_CLUSTER_SLOTS_PER_QUEUE
   global LARGE_CLUSTER_JOB_SIZES LARGE_CLUSTER_JOB_DURATION

   foreach size $LARGE_CLUSTER_JOB_SIZES {
      # shutdown scheduler
      puts $CHECK_OUTPUT "shutting down scheduler"
      shutdown_scheduler $CHECK_HOST [get_qmaster_spool_dir]

      # disable all queues
      large_cluster_disable_queues

      # submit jobs
      if {[string compare $type "usersort"] == 0} {
         large_cluster_submit_jobs $size "$CHECK_USER $CHECK_FIRST_FOREIGN_SYSTEM_USER"
      } else {
         large_cluster_submit_jobs $size
      }

      # initialize scheduler monitoring
      set tail_id [large_cluster_init_monitoring]

      # enable all queues
      large_cluster_enable_queues

      # restart scheduler
      startup_scheduler
      sleep 5
      large_cluster_update_schedd_pid

      # initialize statistic
      large_cluster_statistics start_time start_cpu mem dummy $size

      # gather statistics until all jobs have completed
      puts $CHECK_OUTPUT "waiting for all jobs to finish"
      large_cluster_monitoring $tail_id first_sched total_sched $size

      # get final statistics
      large_cluster_statistics end_time end_cpu mem job_runtime $size

      # check number of jobs scheduled in first run; all slots should be used
      set tasks_submitted [large_cluster_size $size]
      set slots_free [expr ($CHECK_ACT_LEVEL - 300 + 1) * $LARGE_CLUSTER_HOSTS_PER_HOST * $LARGE_CLUSTER_QUEUES_PER_HOST * $LARGE_CLUSTER_SLOTS_PER_QUEUE]
      if {$slots_free < $tasks_submitted} {
         set jobs_to_schedule $slots_free
      } else {
         set jobs_to_schedule $tasks_submitted
      }

      if {$first_sched(fast,$size) != $jobs_to_schedule} {
         add_proc_error large_cluster_process_jobs -3 "first scheduling run scheduled wrong number of tasks: it should have scheduled $jobs_to_schedule tasks, but only scheduled $first_sched(fast,$size) tasks"
      }

      # output some statistics
      puts $CHECK_OUTPUT "qmaster cpu: [expr $end_cpu(qmaster,$size) - $start_cpu(qmaster,$size)]"
      puts $CHECK_OUTPUT "schedd  cpu: [expr $end_cpu(schedd,$size) - $start_cpu(schedd,$size)]"
      puts $CHECK_OUTPUT "total runtime: [expr $end_time($size) - $start_time($size)]"
      puts $CHECK_OUTPUT "first scheduling: $first_sched(time,$size) s, $first_sched(fast,$size) jobs, $first_sched(orders,$size) orders"
      puts $CHECK_OUTPUT "total scheduling: $total_sched(time,$size) s, $total_sched(fast,$size) jobs, $total_sched(orders,$size) orders"
      puts $CHECK_OUTPUT "avg   scheduling: [expr $total_sched(time,$size) * 1000.0 / $total_sched(fast,$size)] ms/jobs, [expr $total_sched(time,$size) * 1000.0 / $total_sched(orders,$size)] ms/order"
   }

   # write statistics to file
   large_cluster_write_statistics $type $LARGE_CLUSTER_JOB_SIZES start_time end_time start_cpu end_cpu mem first_sched total_sched job_runtime
}

proc large_cluster_setup_sharetree {size} {
   global CHECK_OUTPUT CHECK_PRODUCT_ROOT CHECK_ARCH CHECK_USER CHECK_FIRST_FOREIGN_SYSTEM_USER
   global project_list

   # delete old sharetree
   del_sharetree

   # delete all projects
   puts $CHECK_OUTPUT "removing all projects"
   catch { exec "$CHECK_PRODUCT_ROOT/bin/$CHECK_ARCH/qconf" "-sprjl" } result
   if { [string first "no project list defined" $result] >= 0 } {
      puts $CHECK_OUTPUT "no project defined"
   } else {
      foreach elem $result {
         del_prj $elem 
         puts -nonewline $CHECK_OUTPUT "."
      }
      puts ""
   }

   set project_list {}

   # delete all users
   puts $CHECK_OUTPUT "removing all users"
   catch { exec "$CHECK_PRODUCT_ROOT/bin/$CHECK_ARCH/qconf" "-suserl" } result
   if { [string first "no user list defined" $result] >= 0 } {
      puts $CHECK_OUTPUT "no users defined"
   } else {
      foreach elem $result {
         del_user $elem 
         puts -nonewline $CHECK_OUTPUT "."
      }
      puts ""
   }

   # add users
   set new_user(name) $CHECK_USER
   add_user new_user

   set new_user(name) $CHECK_FIRST_FOREIGN_SYSTEM_USER
   add_user new_user
   
   for {set i 0} {$i < $size} {incr i} {
      # add project
      set project [format "project_%05d" $i]
      set new_project(name) $project
      add_prj new_project

      lappend project_list $project

      catch {exec "$CHECK_PRODUCT_ROOT/bin/$CHECK_ARCH/qconf" "-astnode" "/$project=[expr $i + 10],/$project/$CHECK_USER=30,/$project/$CHECK_FIRST_FOREIGN_SYSTEM_USER=70"} result
      puts $CHECK_OUTPUT $result
   }
}

proc large_cluster_sharetree {} {
   global CHECK_OUTPUT CHECK_PRODUCT_ROOT CHECK_ARCH CHECK_USER CHECK_FIRST_FOREIGN_SYSTEM_USER CHECK_HOST
   global CHECK_PRODUCT_TYPE
   global LARGE_CLUSTER_POLICIES_PROJECTS LARGE_CLUSTER_POLICIES_JOBS LARGE_CLUSTER_JOB_DURATION  
   global project_list

   if { [ string compare $CHECK_PRODUCT_TYPE "sgeee" ] != 0 } {
      set_error -3 "not available for sge system"
      return
   }

   if {[info exists start_time]} {
      unset start_time
   }
   if {[info exists start_cpu]} {
      unset start_cpu
   }
   if {[info exists end_cpu]} {
      unset end_cpu
   }
   if {[info exists mem]} {
      unset mem
   }

   foreach size $LARGE_CLUSTER_POLICIES_PROJECTS {
      # shutdown scheduler
      puts $CHECK_OUTPUT "shutting down scheduler"
      shutdown_scheduler $CHECK_HOST [get_qmaster_spool_dir]

      # setup sharetree
      large_cluster_setup_sharetree $size
   
      # disable all queues
      large_cluster_disable_queues

      # submit jobs
      large_cluster_submit_jobs $LARGE_CLUSTER_POLICIES_JOBS "$CHECK_USER $CHECK_FIRST_FOREIGN_SYSTEM_USER" $project_list

      # initialize scheduler monitoring
      set tail_id [large_cluster_init_monitoring]

      # enable all queues
      large_cluster_enable_queues

      # restart scheduler
      startup_scheduler
      sleep 5
      large_cluster_update_schedd_pid

      # initialize statistic
      large_cluster_statistics start_time start_cpu mem dummy $size

      # gather statistics until all jobs have completed
      puts $CHECK_OUTPUT "waiting for all jobs to finish"
      large_cluster_monitoring $tail_id first_sched total_sched $size

      # get final statistics
      large_cluster_statistics end_time end_cpu mem job_runtime $size

      puts $CHECK_OUTPUT "qmaster cpu: [expr $end_cpu(qmaster,$size) - $start_cpu(qmaster,$size)]"
      puts $CHECK_OUTPUT "schedd  cpu: [expr $end_cpu(schedd,$size) - $start_cpu(schedd,$size)]"
      puts $CHECK_OUTPUT "total runtime: [expr $end_time($size) - $start_time($size)]"
      puts $CHECK_OUTPUT "first scheduling: $first_sched(time,$size) s, $first_sched(fast,$size) jobs, $first_sched(orders,$size) orders"
      puts $CHECK_OUTPUT "total scheduling: $total_sched(time,$size) s, $total_sched(fast,$size) jobs, $total_sched(orders,$size) orders"
      puts $CHECK_OUTPUT "avg   scheduling: [expr $total_sched(time,$size) * 1000.0 / $total_sched(fast,$size)] ms/jobs, [expr $total_sched(time,$size) * 1000.0 / $total_sched(orders,$size)] ms/order"
   }

   # write statistics to file
   large_cluster_write_statistics stree $LARGE_CLUSTER_POLICIES_PROJECTS start_time end_time start_cpu end_cpu mem first_sched total_sched job_runtime

   set_error 0 "ok"
}

proc large_cluster_update_schedd_pid {} {
   global pids qmaster_spool_dir

   set f [open "$qmaster_spool_dir/schedd/schedd.pid" r]
   gets $f pids(schedd)
   close $f
}

proc large_cluster_setup {} {
   global CHECK_OUTPUT CHECK_HOST CHECK_ACTUAL_TEST_PATH CHECK_ACT_LEVEL
   global CHECK_PRODUCT_TYPE
   global LARGE_CLUSTER_JOB_SIZES LARGE_CLUSTER_POLICIES_PROJECTS
   global qmaster_spool_dir pids

   set qmaster_spool_dir [get_qmaster_spool_dir]

   set f [open "$qmaster_spool_dir/qmaster.pid" r]
   gets $f pids(qmaster)
   close $f

   set f [open "$qmaster_spool_dir/schedd/schedd.pid" r]
   gets $f pids(schedd)
   close $f

   # initial protocol files
   puts $CHECK_OUTPUT "initializing protocol files"
   if {$CHECK_ACT_LEVEL == 300} {
      # global targets
      foreach target "memory" {
         set content "hosts\tqmaster\tscheduler"
         large_cluster_write_file global $target $content w
      }
      # check targets
      foreach target "runtime cpu_qmaster cpu_schedd first_jobs avg_jobs avg_orders utilization" {
         set content hosts
         foreach i $LARGE_CLUSTER_JOB_SIZES {
            append content "\t$i"
         }
         large_cluster_write_file job $target $content w
         large_cluster_write_file throughput $target $content w
         large_cluster_write_file usersort $target $content w

         if {[string compare $CHECK_PRODUCT_TYPE sgeee] == 0} {
            set content hosts
            foreach i $LARGE_CLUSTER_POLICIES_PROJECTS {
               append content "\t$i"
            }
            large_cluster_write_file stree $target $content w
         }
      }
   }

   # remove default setup
   puts $CHECK_OUTPUT "removing the default testsuite setup"
   large_cluster_remove_default

   # hostcomplex, variabel simhost
   puts $CHECK_OUTPUT "setting up host complex"
   if {[info exists host_complex]} {
      unset host_complex
   }
   if {[info exists new_host_complex]} {
      unset new_host_complex
   }
   get_complex host_complex host
   if {![info exists host_complex(simhost)]} {
      set new_host_complex(simhost) "sh HOST $CHECK_HOST == YES NO $CHECK_HOST"
      set_complex new_host_complex host
   }

   # create simulation hosts
   puts $CHECK_OUTPUT "creating simulated hosts"
   large_cluster_create_hosts

   # qmaster param simulate_hosts and setup loadsensor
   if {[info exists config]} {
      unset config
   }
   if {[info exists new_config]} {
      unset new_config
   }
   puts $CHECK_OUTPUT "setting up cluster configuration"
   get_config config
   # simulate_hosts not yet set
   if {[string first simulate_hosts $config(qmaster_params)] < 0} {
      if {[string compare -nocase $config(qmaster_params) none] == 0} {
         set new_config(qmaster_params) "simulate_hosts=1"
      } else {
         set new_config(qmaster_params) "$config(qmaster_params) simulate_hosts=1"
      }
   }

   set new_config(schedd_params) "FLUSH_SUBMIT_SEC=5,FLUSH_FINISH_SEC=5,profile=1"
   set new_config(load_sensor) "$CHECK_ACTUAL_TEST_PATH/loadsensor"
   set new_config(loglevel) "log_warning"
   set_config new_config
  

   # in case of sgeee, set sharetree tickets
   if {[string compare $CHECK_PRODUCT_TYPE sgeee] == 0} {
      if {[info exists new_schedd_config]} {
         unset new_schedd_config
      }
      set new_schedd_config(weight_tickets_share) 10000
      set_schedd_config new_schedd_config
   }
  
   # create queues
   puts $CHECK_OUTPUT "creating queues"
   large_cluster_create_queues

   wait_for_load_from_all_queues 300
}

proc large_cluster_create_hosts {} {
   global CHECK_OUTPUT LARGE_CLUSTER_HOSTS_PER_HOST LARGE_CLUSTER_HOST_PREFIX
   global CHECK_PRODUCT_ROOT CHECK_ARCH
   global real_hosts

   set first 0
   foreach host $real_hosts {
      # set simhost for complex_value for real host
      catch {exec "$CHECK_PRODUCT_ROOT/bin/$CHECK_ARCH/qconf" "-mattr" "exechost" "complex_values" "simhost=$host" "$host"}

      # create simulated host
      puts $CHECK_OUTPUT "creating $LARGE_CLUSTER_HOSTS_PER_HOST simulated hosts for real host $host"
      for {set i $first}  {$i < [expr $first + $LARGE_CLUSTER_HOSTS_PER_HOST]} {incr i} {
         if {[info exists new_host]} {
            unset new_host
         }
         set new_host(hostname) [format "%s%05d" $LARGE_CLUSTER_HOST_PREFIX $i]
         set new_host(complex_values) "simhost=$host"
         add_exechost new_host 1
      }

      incr first $LARGE_CLUSTER_HOSTS_PER_HOST
   }
}

proc large_cluster_create_queues {} {
   global CHECK_OUTPUT
   global LARGE_CLUSTER_QUEUES_PER_HOST LARGE_CLUSTER_SLOTS_PER_QUEUE 
   global LARGE_CLUSTER_HOSTS_PER_HOST LARGE_CLUSTER_HOST_PREFIX
   global real_hosts queue_list

   if {[info exists queue_list]} {
      unset queue_list
   }

   set first 0
   foreach host $real_hosts {
      puts $CHECK_OUTPUT "creating $LARGE_CLUSTER_QUEUES_PER_HOST queues for each host on real host $host"
      for {set i $first}  {$i < [expr $first + $LARGE_CLUSTER_HOSTS_PER_HOST]} {incr i} {
         for {set j 0} {$j < $LARGE_CLUSTER_QUEUES_PER_HOST} {incr j} {
            if {[info exists new_queue]} {
               unset new_queue
            }
            set simhost [format "%s%05d" $LARGE_CLUSTER_HOST_PREFIX $i]
            set queue   [format "%s_%d" $simhost $j]
            set new_queue(qname)    "$queue"
            set new_queue(hostname) "$simhost"
            set new_queue(slots)    $LARGE_CLUSTER_SLOTS_PER_QUEUE
            set new_queue(load_thresholds) "np_load_avg=10.0"

            add_queue new_queue 1

            lappend queue_list $queue
         }
      }
      incr first $LARGE_CLUSTER_HOSTS_PER_HOST
   }
}

proc large_cluster_remove_default {} {
   global CHECK_OUTPUT CHECK_PRODUCT_ROOT CHECK_ARCH
   global LARGE_CLUSTER_HOST_PREFIX

   # remove all ckpt
   puts $CHECK_OUTPUT "removing all checkpointing environments"
   catch { exec "$CHECK_PRODUCT_ROOT/bin/$CHECK_ARCH/qconf" "-sckptl" } result
   if { [string first "no ckpt interface definition defined" $result] >= 0 } {
      puts $CHECK_OUTPUT "no checkpointing interface defined"
   } else {
      foreach elem $result {
         puts -nonewline $CHECK_OUTPUT "$elem "
         del_checkpointobj $elem 
      }
      puts ""
   }
   
   # remove all pe
   puts $CHECK_OUTPUT "removing all parallel environments"
   catch { exec "$CHECK_PRODUCT_ROOT/bin/$CHECK_ARCH/qconf" "-spl" } result
   if { [string first "no parallel environment defined" $result] >= 0 } {
      puts $CHECK_OUTPUT "no parallel environment defined"
   } else {
      foreach elem $result {
         puts -nonewline $CHECK_OUTPUT "$elem "
         del_pe $elem 
      }
      puts ""
   }

   # remove all queues
   puts $CHECK_OUTPUT "removing all queues"
   catch { exec "$CHECK_PRODUCT_ROOT/bin/$CHECK_ARCH/qconf" "-sql" } result
   if { [string first "no queue defined" $result] >= 0 } {
      puts $CHECK_OUTPUT "no queue defined"
   } else {
      foreach elem $result {
         puts -nonewline $CHECK_OUTPUT "." ; flush $CHECK_OUTPUT
         del_queue $elem 
      }
      puts ""
   }

   # remove all simulated hosts
   puts $CHECK_OUTPUT "removing all simulated hosts"
   catch { exec "$CHECK_PRODUCT_ROOT/bin/$CHECK_ARCH/qconf" "-sel" } result
   foreach elem $result {
      if {[string first $LARGE_CLUSTER_HOST_PREFIX $elem] >= 0} {
         catch {exec "$CHECK_PRODUCT_ROOT/bin/$CHECK_ARCH/qconf" "-de" "$elem"}
         puts -nonewline $CHECK_OUTPUT "." ; flush $CHECK_OUTPUT
      }
   }
   puts ""

   set_error 0 "ok"
}

proc large_cluster_cleanup {} {
   global CHECK_ACTUAL_TEST_PATH CHECK_CHECKTREE_ROOT CHECK_OUTPUT CHECK_PRODUCT_ROOT CHECK_ARCH CHECK_ACT_LEVEL
   global LARGE_CLUSTER_HOST_PREFIX CHECK_PRODUCT_TYPE 
   global check_highest_level check_needs check_name check_errstr
   global check_description check_functions check_errno check_init_level_procedure check_use_installed_system

   # dump html code
   large_cluster_create_html

   # reinit system

   # restore cluster configuration
   puts $CHECK_OUTPUT "reset cluster configuration"
   set new_config(qmaster_params) "none"
   set new_config(schedd_params) "none"
   set new_config(load_sensor)    "none"
   set_config new_config
  
   # restore cluster configuration
   if {[string compare $CHECK_PRODUCT_TYPE sgeee] == 0} {
      puts $CHECK_OUTPUT "reset scheduler configuration"
      set new_schedd_config(weight_tickets_share) 0
      set_schedd_config new_schedd_config
   }

   # backup check variables
   foreach var "check_needs check_name check_errstr check_description check_functions check_errno check_init_level_procedure check_use_installed_system CHECK_ACTUAL_TEST_PATH check_highest_level" {
      upvar 0 $var value
      if {[array exists value]} {
         foreach i [array names value] {
            set large_cluster_backup_${var}($i) $value($i)
         }
      } else {
         set large_cluster_backup_${var} $value
      }   
   }
  
   # start install re_init
   unlock_testsuite
   set check_use_installed_system 1
   set CHECK_ACT_PATH "$CHECK_CHECKTREE_ROOT/install_core_system"  
   run_test $CHECK_ACT_PATH 1

   # restore check variables
   foreach var "check_needs check_name check_errstr check_description check_functions check_errno check_init_level_procedure check_use_installed_system CHECK_ACTUAL_TEST_PATH check_highest_level" {
      upvar 0 $var variable
      upvar 0 large_cluster_backup_${var} value
      if {[array exists value]} {
         foreach i [array names value] {
            set variable($i) $value($i)
         }
      } else {
         set variable $value
      }
   }

   # remove all simulated hosts
   puts $CHECK_OUTPUT "removing all simulated hosts"
   catch { exec "$CHECK_PRODUCT_ROOT/bin/$CHECK_ARCH/qconf" "-sel" } result
   foreach elem $result {
      if {[string first $LARGE_CLUSTER_HOST_PREFIX $elem] >= 0} {
         catch {exec "$CHECK_PRODUCT_ROOT/bin/$CHECK_ARCH/qconf" "-de" "$elem"}
         puts -nonewline $CHECK_OUTPUT "." ; flush $CHECK_OUTPUT
      }
   }
   puts ""

   set_error 0 "ok"
}

proc large_cluster_global {} {
   global CHECK_OUTPUT CHECK_ACT_LEVEL
   global LARGE_CLUSTER_HOSTS_PER_HOST

   puts $CHECK_OUTPUT "retrieving memory consumption"
   large_cluster_statistics dummy1 dummy2 mem dummy3 global
   set line "[expr ($CHECK_ACT_LEVEL - 300 + 1) * $LARGE_CLUSTER_HOSTS_PER_HOST]\t$mem(qmaster,global)\t$mem(schedd,global)"
   large_cluster_write_file global memory $line
   set_error 0 "ok"
}

#=========================================
# create HTML report
#=========================================

proc large_cluster_create_chart {report_dir html title check data gnuplot} {
   global CHECK_OUTPUT CHECK_PROTOCOL_DIR

   puts $CHECK_OUTPUT "creating chart for check $check, datatype $data"
   set datafile    "$CHECK_PROTOCOL_DIR/gnuplot.dat"
   set commandfile "$CHECK_PROTOCOL_DIR/gnuplot.cmd"
   set giffile     "large_cluster_${check}_${data}.gif"

   # dump data file
   set input [open "$CHECK_PROTOCOL_DIR/large_cluster_${check}_${data}.txt" r]
   set output [open $datafile w]

   # labels for x axis
   gets $input line
   set labels [lrange $line 1 end]
   set xtics "("
   set counter 1
   foreach label $labels {
      if {$counter == 1} {
         append xtics "\"$label\" $counter"
      } else {
         append xtics ",\"$label\" $counter"
      }
      incr counter
   }
   append xtics ")"

   set hostcounts {}
   while {[gets $input line] > 0} {
      lappend hostcounts [lindex $line 0]
      set counter 1
      foreach sample [lrange $line 1 end] {
         puts $output "$counter $sample"
         incr counter
      }
      puts $output "\n"
   }

   close $input
   close $output

   # dump command file

   set drawstyle linespoints

   switch -exact $check {
      job -
      usersort -
      throughput {
         set xlabel "jobs"
      }
      stree {
         set xlabel "size of sharetree (n * 3)"
      }
      global {
         set xlabel "daemon"
         set drawstyle points
      }
      default {
         set xlabel "unknown"
      }
   }

   switch -exact $data {
      avg_jobs {
         set ylabel "time \[ms\]"
      }
      avg_orders {
         set ylabel "time \[ms\]"
      }
      cpu_qmaster {
         set ylabel "cpu time \[s\]"
      }
      cpu_schedd {
         set ylabel "cpu time \[s\]"
      }
      memory {
         set ylabel "virtual size \[MB\]"
      }
      first_jobs {
         set ylabel "time \[s\]"
      }
      runtime {
         set ylabel "time \[s\]"
      }
      utilization {
         set ylabel "utilization \[%\]"
      }
      default {
         set ylabel "unknown"
      }
   }
   
   set f [open "$commandfile" w]
   puts $f "set terminal gif"
   puts $f "set output '$report_dir/$giffile'"
   puts $f "set xtics $xtics"
   puts $f "set xlabel \"$xlabel\""
   puts $f "set ylabel \"$ylabel\""
   puts $f "set title \"$title"
   set counter 0
   puts -nonewline $f "plot "
   foreach hostcount $hostcounts {
      if {$counter > 0} {
         puts -nonewline $f ", "
      }
      puts -nonewline $f "'$datafile' index $counter title \"$hostcount\" with $drawstyle" 
      incr counter
   }
   puts $f ""
   close $f

   # wait for NFS
   sleep 5
  
   # call gnuplot
   set returncode [catch {exec $gnuplot $commandfile} output]
   if {$returncode != 0} {
      add_proc_error large_cluster_create_chart -3 "calling gnuplot failed: $output"
   }
  
   # cleanup
   file delete $datafile
   file delete $commandfile

   # write html
   puts $html "<P><IMG SRC=\"$giffile\" NAME=\"$title\" ALIGN=LEFT BORDER=0><BR CLEAR=LEFT><BR><BR></P>"
}

proc large_cluster_dump_data {html check data} {
   global CHECK_OUTPUT CHECK_PROTOCOL_DIR

   puts $CHECK_OUTPUT "dumping data for check $check, datatype $data"

   set input [open "$CHECK_PROTOCOL_DIR/large_cluster_${check}_${data}.txt" r]
   gets $input line

   puts $html "<TABLE WIDTH=100% BORDER=1 CELLPADDING=4 CELLSPACING=3>"
   puts $html "<THEAD>"
   puts $html "<TR>"
   foreach data $line {
      puts $html "<TH> $data </TH>"
   }
   puts $html "</TR>"
   puts $html "</THEAD>"
   while {[gets $input line] > 0} {
      puts $html "<TR>"
      foreach data $line {
         puts $html "<TD> <P ALIGN=RIGHT> [format "%.3f" $data] </P> </TD>"
      }
      puts $html "</TR>"
   }
   puts $html "</TABLE>"

   close $input
}

proc large_cluster_create_html {} {
   global CHECK_HOST CHECK_PROTOCOL_DIR CHECK_OUTPUT CHECK_PRODUCT_TYPE

   # check prerequisits
   set gnuplot [get_binary_path $CHECK_HOST "gnuplot"]

   set report_dir "$CHECK_PROTOCOL_DIR/HTML"
   if {![file exists $report_dir]} {
      file mkdir $report_dir
   }

   # create HTML file
   set output [open "$report_dir/large_cluster.html" w]
   puts $output "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 3.2//EN\">"
   puts $output "<HTML>"
   puts $output "<HEAD>"
   puts $output "	<META HTTP-EQUIV=\"CONTENT-TYPE\" CONTENT=\"text/html; charset=iso-8859-1\">"
   puts $output "	<TITLE>Testsuite Results - Large Cluster Performance and Scalability</TITLE>"
   puts $output "	<META NAME=\"GENERATOR\" CONTENT=\"Grid Engine Testsuite\">"
   puts $output "</HEAD>"
   puts $output "<BODY>"
   puts $output "<H1>Large Cluster Performance and Scalability</H1>"

   # create global information
   puts $output "<H2>Global information</H2>"
   puts $output "<P>... description ...</P>"

   # memory consumption
   puts $output "<H3>Memory consumption of qmaster and scheduler</H3>"
   large_cluster_dump_data $output global memory
   large_cluster_create_chart $report_dir $output "Size of qmaster and scheduler dependent on the number of hosts" global memory $gnuplot

   # create charts for checks
   set check_types {job throughput}
   if {[string compare $CHECK_PRODUCT_TYPE "sgeee"] == 0 } {
      lappend check_types stree
   }
   if {[string compare $CHECK_PRODUCT_TYPE "sge"] == 0 } {
      lappend check_types usersort
   }

   foreach check_type $check_types {
      set checktitle "dependent on number of hosts"

      switch -exact -- $check_type {
         job {
            set checktitle "$checktitle and number of jobs"
            puts $output "<H2>Dependent on number of hosts and number of jobs</H2>"
            puts $output "<P>... description ...</P>"
         }
         throughput {
            set checktitle "$checktitle and number of jobs"
            puts $output "<H2>Dependent on number of hosts and number of jobs</H2>"
            puts $output "<P>in a throughput cluster (no load adjustment, no load thresholds)</P>"
         }
         usersort {
            set checktitle "$checktitle and number of jobs"
            puts $output "<H2>Dependent on number of hosts and number of jobs</H2>"
            puts $output "<P>in a cluster with usersort enabled</P>"
         }
         stree {
            set checktitle "$checktitle and size of a sharetree"
            puts $output "<H2>Dependent on number of hosts and the size of a sharetree</H2>"
            puts $output "<P>... description ...</P>"
         }
         default {
            puts $CHECK_OUTPUT "---> default"
            set title  "unknown test"
            puts $output "<H2>Unknown check</H2>"
         }
      }
   
      foreach data "avg_jobs avg_orders cpu_qmaster cpu_schedd first_jobs runtime utilization" {
         switch -exact $data {
            avg_jobs {
               set title "average time to schedule a job $checktitle"
            }
            avg_orders {
               set title "average time to create an order $checktitle"
            }
            cpu_qmaster {
               set title "cpu time consumed by qmaster $checktitle"
            }
            cpu_schedd {
               set title "cpu time consumed by scheduler $checktitle"
            }   
            mem_qmaster {
               set title "virtual memory size of qmaster $checktitle"
            }
            mem_schedd {
               set title "virtual memory size of scheduler $checktitle"
            }   
            first_jobs {
               set title "time for first scheduling $checktitle"
            }
            runtime {
               set title "total runtime $checktitle"
            }
            utilization {
               set title "utilization $checktitle"
            }
            default {
               set title "unknown data of $checktitle"
            }
         }

         puts $output "<H3> $title </H3>"
         large_cluster_dump_data $output $check_type $data
         large_cluster_create_chart $report_dir $output $title $check_type $data $gnuplot
      }
   }

   puts $output "</BODY>"
   puts $output "</HTML>"
   close $output

   set_error 0 "ok"
}


