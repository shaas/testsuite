#!/vol2/TCL_TK/glinux/bin/expect
# ___INFO__MARK_BEGIN__
##########################################################################
#
#  The Contents of this file are made available subject to the terms of
#  the Sun Industry Standards Source License Version 1.2
#
#  Sun Microsystems Inc., March, 2001
#
#
#  Sun Industry Standards Source License Version 1.2
#  =================================================
#  The contents of this file are subject to the Sun Industry Standards
#  Source License Version 1.2 (the "License"); You may not use this file
#  except in compliance with the License. You may obtain a copy of the
#  License at http://gridengine.sunsource.net/Gridengine_SISSL_license.html
#
#  Software provided under this License is provided on an "AS IS" basis,
#  WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING,
#  WITHOUT LIMITATION, WARRANTIES THAT THE SOFTWARE IS FREE OF DEFECTS,
#  MERCHANTABLE, FIT FOR A PARTICULAR PURPOSE, OR NON-INFRINGING.
#  See the License for the specific provisions governing your rights and
#  obligations concerning the Software.
#
#  The Initial Developer of the Original Code is: Sun Microsystems, Inc.
#
#  Copyright: 2006 by Sun Microsystems, Inc
#
#  All Rights Reserved.
#
##########################################################################
# ___INFO__MARK_END__


# source version dependent parts of the installation
global CHECK_ACTUAL_TEST_PATH CHECK_TESTSUITE_INSTALL_MODE
global check_name check_description check_needs check_functions
global check_root_access_needs check_category      
global check_use_installed_system check_init_level_procedure

# This file shows some check spezific things
# ---START OF TEST INFO SECTION-------------------------------------------------------------------------------
# "no" - we don't need root acess / "yes" - we need root access:
set check_root_access_needs    "no"              

# name of the test (best practice: use the name of the test directory)
set check_name                 "show_status"

# specifiy the test categories
# (VERIFIED if the test is QA inspected)
# other possible categories: COMPATIBILITY CSP INSTALL L10N MODULE PERFORMANCE SYSTEM VERIFIED
set check_category             "SYSTEM VERIFIED" 

# define the highest check level
set check_highest_level        0

# a sort check description for each runlevel:
# (runlevel 0 is mandatory)
set check_description(0)       "check all sdmadm show_status options" ;# runlevel 0
# set check_description(1)       "SOME OTHER DESCRIPTION"  ;# runlevel 1

# specify check dependencies
# (name all tests which have to run sucessfull before this test can run)
set check_needs                "hedeby_install"                  

# The name of the init level procedure for this test. The procedure is defined
# in the test file. 
set check_init_level_procedure "show_status_init_level"

# define tests setup and cleanup function. The functions are called for each
# runlevel. Before testsuite is starting with calling all check_functions
# the setup function is called. After finishing all check_functions the 
# cleanup function is called.
#
# The aim of the setup/cleanup functions is that the test should restore
# all modifications, even when the test failes completely.
set check_setup_function "show_status_setup"
set check_cleanup_function "show_status_cleanup"


# The check_functions array tells the testsuite which check functions should
# be called (and in which order)
# All check_functions should be defined at least in a file (*.tcl) in the
# check directory.
set check_functions            ""
lappend check_functions "show_status_check"


# ---END OF TEST INFO SECTION-------------------------------------------------------------------------------


# ---------------------------------------------------------------------------------
# here the tests begin ....
global show_status_current_cluster_config

# (the init level procedure defines which runlevels are supported)
# short  (   0 min - 15 min / run level   0 -  99 )"
# medium (  16 min -  1 h   / run level 100 - 199 )"
# long   (   1 h   -  4 h   / run level 200 - 299 )"
# day    ( > 4 h   - 24 h   / run level 300 - 399 )"
# week   ( >24 h            / run level 400 - 499 )"
proc show_status_init_level {} {
  global CHECK_ACT_LEVEL

  # this test currently supports only runlevel "0"
  if { $CHECK_ACT_LEVEL == 0 } {
     return 0
  }
  return -1
}

# the setup function for this test is storing the current
# cluster config nr in a global variable.
proc show_status_setup {} {
   global CHECK_OUTPUT
   global show_status_current_cluster_config
   
   puts $CHECK_OUTPUT "doing setup ..."
   set show_status_current_cluster_config [get_current_cluster_config_nr]
}

# the cleanup function for this test will restore the
# current cluster config nr from the global variable set 
# be the setup function.
proc show_status_cleanup {} {
   global CHECK_OUTPUT
   global show_status_current_cluster_config

   puts $CHECK_OUTPUT "doing cleanup ..."

   set_current_cluster_config_nr $show_status_current_cluster_config
}


# The test will call the sdmadm show_status command for every 
# hedeby managed host and on the master host.
# If the output does not show all components in the "started"
# status the test will fail.
proc show_status_check {} {
   global CHECK_OUTPUT
   global hedeby_config

   # setup master host expectations ...
   set test_hosts $hedeby_config(hedeby_master_host)
   set expected_jvms($hedeby_config(hedeby_master_host)) "cs_vm executor_vm"
   set expected_components($hedeby_config(hedeby_master_host)) "ca executor"
   set expected_component_status "started"

   # setup managed host expectations ...
   foreach host $hedeby_config(hedeby_host_resources) {
      lappend test_hosts $host
      set expected_jvms($host) "executor_vm"
      set expected_components($host) "executor"
   }

   set nr_of_jvms 0
   set nr_of_components 0
   set error_text ""
   foreach host $test_hosts {
      puts $CHECK_OUTPUT "testing sdmadm show_status on host $host ..."
 
      # we don't use the pref type - hedeby must find the system anyway
      # we also don't need to test the exit state (sdmadm_show_status does it already)
      sdmadm_show_status $host [get_hedeby_admin_user] output "" [get_hedeby_system_name]
      set debug_output($host) $output
      parse_sdmadm_show_status_output output
      # ss_out

      foreach jvm $expected_jvms($host) {
         puts $CHECK_OUTPUT "   checking jvm status of jvm \"$jvm\" on host \"$host\" ..."
         if { [info exists ss_out($host,$jvm,status)] } {
            set status $ss_out($host,$jvm,status)
            set section $ss_out($host,$jvm,section)
            puts $CHECK_OUTPUT "   status:  $status"
            puts $CHECK_OUTPUT "   section: $section"
            if { $status != $expected_component_status } {
               append error_text "jvm \"$jvm\" on host \"$host\" reports status \"$status\".\n"
               append error_text "Expected status is \"$expected_component_status\"!\n"
            }
         } else {
            append error_text "can't find jvm \"$jvm\" on host \"$host\"!\n"
         }
         incr nr_of_jvms 1
      }
      foreach comp $expected_components($host) {
         puts $CHECK_OUTPUT "   checking component statos of component \"$comp\" on host \"$host\" ..."
         if { [info exists ss_out($host,$comp,status)] } {
            set status $ss_out($host,$comp,status)
            set section $ss_out($host,$comp,section)
            puts $CHECK_OUTPUT "   status:  $status"
            puts $CHECK_OUTPUT "   section: $section"
            if { $status != $expected_component_status } {
               append error_text "component \"$comp\" on host \"$host\" reports status \"$status\".\n"
               append error_text "Expected status is \"$expected_component_status\"!\n"
            }
         } else {
            append error_text "can't find component \"$comp\" on host \"$host\"!\n"
         }
         incr nr_of_components 1
      }
   }
   puts $CHECK_OUTPUT "nr of jvms:       $nr_of_jvms"
   puts $CHECK_OUTPUT "nr of components: $nr_of_components"
   puts $CHECK_OUTPUT "nr of status infos: $ss_out(showed_status_count)"

   set sum $nr_of_jvms
   incr sum $nr_of_components
   if { $ss_out(showed_status_count) != $sum } {
      append error_text "Expected info count(=$sum) doesn't match reported info count(= $ss_out(showed_status_count))\n"
   }

   if { $error_text != "" } {
      append error_text "\n\n---debug info (start) -----------------------------------------\n"
      foreach host $test_hosts {
         append error_text "\nsdmadm show_status output on host \"$host\":\n"
         append error_text $debug_output($host)
         append error_text "\n"
      }
      append error_text "---debug info (end) -------------------------------------------"
      add_proc_error "show_status_check" -1 $error_text
   }
}



